{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/calculus-for-brain-computation/",
    "result": {"data":{"mdx":{"id":"a16c55ac-45a3-5741-b6fb-d8e2eb5bdcce","tableOfContents":{"items":[{"url":"#calculus-for-brain-computation","title":"Calculus For Brain Computation"}]},"fields":{"title":"Calculus For Brain Computation","slug":"/calculus-for-brain-computation/","url":"https://deepmind.vercel.app/calculus-for-brain-computation/","editUrl":"https://github.com/dfeng/notes/tree/main/calculus-for-brain-computation.md","lastUpdatedAt":"2022-01-29T14:49:40.000Z","lastUpdated":"1/29/2022","gitCreatedAt":"2022-01-12T12:14:44.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":["neuroscience","biologically_inspired"],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"neuroscience\", \"biologically_inspired\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"calculus-for-brain-computation\"\n  }, \"Calculus For Brain Computation\"), mdx(\"p\", null, \"src: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=_sOgIwyjrOA&feature=youtu.be\"\n  }, \"video\"), \", \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://simons.berkeley.edu/sites/default/files/docs/14061/rpassemblies.pdf\"\n  }, \"pdf\")), mdx(\"figure\", {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"600px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/ccd43ac02dc2fc342e8f8bbc47775946/aaf7f/flies_smell.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"58.00000000000001%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAABdUlEQVQoz22T2W6DQAxF+f9fQ8pbHshUQJoVCAlkZXd1XBkBraURMx77zrV98Z7Pp2DDMOjC3u+31HU9+vu+l/v9Lm3bytQ+n4/eWRzm4ZxaWZTinJM4juXxeEhVVXI8HiUIAomjSIxAnueyXq/le7udPe4ZEIkE8QAM+QJ+u93k9XopOxZxsO26TpqmUTD2I6BR5mWYEAQYgSRer1dNwNe0rbJP01SWZi0bGcLidDopEMkwoWR8gLLnQd/39WxVLc27XC5SlqUmnM/nGSAMuU+SRHa7nbYEf5ZlUhSFkuCOfHI5e3VVS9d2WvKSIYAkAwQgMVVdaTI+APgCSC73f0pe9pB+MRjOsIqiSL9WssllLNkcxpAgpmwMAeQxFm1ZrVbK8L+B6FAMEAYkcwaMZSCwZo+xNy1OBT2bMo13G6fi/XJOS0JziHsTbCRNfmWiJYehhGGow7ApT8seAQ+Hg+z3ewUxISMTfKY79Eg/bXjT384Y/gClH56PNFdkIwAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"How fruit flies remember smells\",\n    \"title\": \"How fruit flies remember smells\",\n    \"src\": \"/static/ccd43ac02dc2fc342e8f8bbc47775946/0a47e/flies_smell.png\",\n    \"srcSet\": [\"/static/ccd43ac02dc2fc342e8f8bbc47775946/8a4e8/flies_smell.png 150w\", \"/static/ccd43ac02dc2fc342e8f8bbc47775946/5a46d/flies_smell.png 300w\", \"/static/ccd43ac02dc2fc342e8f8bbc47775946/0a47e/flies_smell.png 600w\", \"/static/ccd43ac02dc2fc342e8f8bbc47775946/1cfc2/flies_smell.png 900w\", \"/static/ccd43ac02dc2fc342e8f8bbc47775946/c1b63/flies_smell.png 1200w\", \"/static/ccd43ac02dc2fc342e8f8bbc47775946/aaf7f/flies_smell.png 1668w\"],\n    \"sizes\": \"(max-width: 600px) 100vw, 600px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"How fruit flies remember smells\"), \"\\n  \"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"olfactory \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"intelligence\"), \": centring -> random projection (50 to 2000) -> sparsification\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\",\n    \"mathvariant\": \"double-struck\"\n  }, \"R\"), mdx(\"mn\", {\n    parentName: \"msup\"\n  }, \"50\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2192\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\",\n    \"mathvariant\": \"double-struck\"\n  }, \"R\"), mdx(\"mn\", {\n    parentName: \"msup\"\n  }, \"2000\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2192\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \"{\"), mdx(\"mn\", {\n    parentName: \"mrow\"\n  }, \"0\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"separator\": \"true\"\n  }, \",\"), mdx(\"mn\", {\n    parentName: \"mrow\"\n  }, \"1\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mo\", {\n    parentName: \"msup\",\n    \"stretchy\": \"false\"\n  }, \"}\"), mdx(\"mn\", {\n    parentName: \"msup\"\n  }, \"2000\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\mathbb{R}^{50} \\\\to \\\\mathbb{R}^{2000} \\\\to \\\\{0,1\\\\}^{2000}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathbb\"\n  }, \"R\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"5\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"0\"))))))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"\\u2192\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathbb\"\n  }, \"R\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"2\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"0\"))))))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"\\u2192\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1.064108em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen\"\n  }, \"{\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mpunct\"\n  }, \",\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"1\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose\"\n  }, \"}\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.8141079999999999em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"2\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"0\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"0\"))))))))))))), \" (sparsity at the 10% level, thresholding the top).\")), mdx(\"figure\", {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"600px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/4db653ffc2f2326591b689fb509ae6ce/b2c3d/flies_project.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"55.333333333333336%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB/ElEQVQoz52S2W7bMBBF/f//1KKvaeDChRet1mJrpUhtFmUpin0KyXUSoG+9AEFyCB7yzszqfr8zq+s64jimaRrO5zN5ni/7LMuQUnI6nUiSZInPsywkpVTLeZ7laK0XzuoJ7Pt+Ac0Qy7LwfR/XdXEcZ4E9Y0EQcHSPmIGNEdrYprU8ME3TA8h/yuslZiN4B6bxRtP8/eFiNYoIo4hciMV6mqaEYUgURct6nr+qvw/4IiYVJYkWDLZPsTnA+8Squ1wITicy00TMlpNksTgDn5aPxyOyKEiThEIUVF2Jv/vFab9DyYg6TIjyAoRg1bbtAoxclyJN8Xwfz/OQSi6gOW9hEOBHEX6SEMYxb0riBCa/04Db0cUMDF7PNqNIWI3jiOs4mJbFbr/HPBgY2wOuYWPbNtvtloNhINdr9MsLVZaB1nRxQqsahvRE7BlUuz2ZFo8cHoNH9XzP41ynWHXIa7qnH66Mb29cxwGaFsryI4+d5dLsHPT7FV9lJEIhpopV3bYIzyOe2yQPcVXMRniYMqAqS7qypa0aVFMj6/pRON0xXEe67rrAfS3Y1xHDbWR1HUciy+Kw2XAIHPL1mur7D4KtwcbZ8y38yYuzoSoUSkmUUsyF/NAdbvcb0336bOyu72kvF3rdP2wVgkFr2lGTTiXt1P/Th/O95/ga+wO2pDpszq8v7gAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Random projection preserves similarity.\",\n    \"title\": \"Random projection preserves similarity.\",\n    \"src\": \"/static/4db653ffc2f2326591b689fb509ae6ce/0a47e/flies_project.png\",\n    \"srcSet\": [\"/static/4db653ffc2f2326591b689fb509ae6ce/8a4e8/flies_project.png 150w\", \"/static/4db653ffc2f2326591b689fb509ae6ce/5a46d/flies_project.png 300w\", \"/static/4db653ffc2f2326591b689fb509ae6ce/0a47e/flies_project.png 600w\", \"/static/4db653ffc2f2326591b689fb509ae6ce/1cfc2/flies_project.png 900w\", \"/static/4db653ffc2f2326591b689fb509ae6ce/c1b63/flies_project.png 1200w\", \"/static/4db653ffc2f2326591b689fb509ae6ce/b2c3d/flies_project.png 2584w\"],\n    \"sizes\": \"(max-width: 600px) 100vw, 600px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Random projection preserves similarity.\"), \"\\n  \"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"similarity is preserved by this (random-projection+threshold) procedure; similarity here defined by overlap\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"not really sure what you're gaining though? \", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Calculus of the Brain\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"interesting experiment: have a neuron only fire when you see Eiffel tower (vs house or Obama)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"then super-impose Obama onto Eiffel tower, see below\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"now show Obama, and the neuron will fire (most of the time)\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"what's going on?\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"one way you can think of this is that there's the set of neurons that fire for Eiffel (memory of Eiffel), and similarly for other objects\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"when you see two things together (learning relationships, causality, hierarchy), then what happens is that these two sets of neurons are now connected/merged\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"but in order for this to make sense, the merge operation needs to be a little bit elaborate. basically you have to create the merged version (so like Eiffel+Obama), and perhaps that becomes the channel that connects the two things?\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"this basically gives you something like a calculus on the brain, basically involving set operations on neurons\")))), mdx(\"figure\", {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"600px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/e0088f5184f1088de95eec91204ad641/96191/obamatowerexperiment.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAACKklEQVQ4y41STW8SURTlX/g/XLpx6S9w48Y0mpiY1GU3Jl3YxDbtgmoEo4uqK0cK1FqkpQZrooaClobPGTvAoAxhBhykzAgDM2+OeW+k9IMab3LmvXvn3jPnvTkeHAvHcdhq2zby+TxqtRoURUGlUmEolUqoVqusXi6XMRgMTszR8EwipEGHKEGj0UChUIAoiizPZrOMtFgsotfr/ZuQBiGEraqqIpFIgOf5I3JZliGKJWQyGQiCMFEIIySOMwZxMRhasAlhzSOc9/Hj7z2TGs8LVVXA8wLS6X1omnZGnUsIB/G9Jt6l2vhc/I1YqoX5LRkz61VwHxs41IesMZfLg+NCCATW8IoLIxyKQJIkV6ltjxXShz8q4clWHZs5E7Mvkrj4MI2ZNyoiKQ3trskaV4NrWFnhENv+hM14AhuRHQRD6zj9Uz2Ag6LcRVbu4UAHfC83ENsTkS/wKB+4F3/Y6TA18fcfsLjwANyiD94lH54+8mOgtWDUvsM2+65Cy7Lx2L+M6PZrfBUleGfvIhZcRfSZF9m3z1mTojRQr9fZ/stuEnM3b2N+bgH7yV1YnV/Q5R+wTXN85Ok713D5ygXcmr6E5aWruH/vOm5MTSEaDoDejGmazIu6rjPTCxUJarMJmziTjgz0zZ/oGhUYPQF96xuamsDM22o1jyxhGAartdttNkxzy7IoC5y/9vpv24x6qEIKGsPh0CU87UO3QE6AUJBR7pzx23l7SvgHl/fCscj8oJIAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Ison et al. 2016 Experiment\",\n    \"title\": \"Ison et al. 2016 Experiment\",\n    \"src\": \"/static/e0088f5184f1088de95eec91204ad641/0a47e/obamatowerexperiment.png\",\n    \"srcSet\": [\"/static/e0088f5184f1088de95eec91204ad641/8a4e8/obamatowerexperiment.png 150w\", \"/static/e0088f5184f1088de95eec91204ad641/5a46d/obamatowerexperiment.png 300w\", \"/static/e0088f5184f1088de95eec91204ad641/0a47e/obamatowerexperiment.png 600w\", \"/static/e0088f5184f1088de95eec91204ad641/1cfc2/obamatowerexperiment.png 900w\", \"/static/e0088f5184f1088de95eec91204ad641/c1b63/obamatowerexperiment.png 1200w\", \"/static/e0088f5184f1088de95eec91204ad641/96191/obamatowerexperiment.png 2176w\"],\n    \"sizes\": \"(max-width: 600px) 100vw, 600px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Ison et al. 2016 Experiment\"), \"\\n  \"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"I guess, the idea is that you have a sparse representation (binary vector that can be captured by binary-firing neurons). perhaps storage, like with computers, just has to be in binary, so there's nothing particularly profound here.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\ntags:\n - neuroscience\n - biologically_inspired\n---\n\n# Calculus For Brain Computation\n\nsrc: [video](https://www.youtube.com/watch?v=_sOgIwyjrOA&feature=youtu.be), [pdf](https://simons.berkeley.edu/sites/default/files/docs/14061/rpassemblies.pdf)\n\n![How fruit flies remember smells](img/flies_smell.png)\n\n - olfactory *intelligence*: centring -> random projection (50 to 2000) -> sparsification\n - $\\mathbb{R}^{50} \\to \\mathbb{R}^{2000} \\to \\{0,1\\}^{2000}$ (sparsity at the 10% level, thresholding the top).\n\n![Random projection preserves similarity.](img/flies_project.png)\n\n - similarity is preserved by this (random-projection+threshold) procedure; similarity here defined by overlap\n   + not really sure what you're gaining though? ^[I guess, the idea is that you have a sparse representation (binary vector that can be captured by binary-firing neurons). perhaps storage, like with computers, just has to be in binary, so there's nothing particularly profound here.]\n\n - Calculus of the Brain\n   + interesting experiment: have a neuron only fire when you see Eiffel tower (vs house or Obama)\n     * then super-impose Obama onto Eiffel tower, see below\n     * now show Obama, and the neuron will fire (most of the time)\n   + what's going on?\n     * one way you can think of this is that there's the set of neurons that fire for Eiffel (memory of Eiffel), and similarly for other objects\n     * when you see two things together (learning relationships, causality, hierarchy), then what happens is that these two sets of neurons are now connected/merged\n     * but in order for this to make sense, the merge operation needs to be a little bit elaborate. basically you have to create the merged version (so like Eiffel+Obama), and perhaps that becomes the channel that connects the two things?\n   + this basically gives you something like a calculus on the brain, basically involving set operations on neurons\n\n![Ison et al. 2016 Experiment](img/obamatowerexperiment.png)","excerpt":"Calculus For Brain Computation src:  video ,  pdf olfactory  intelligence : centring -> random projection (50 to 2000) -> sparsification  (â€¦","outboundReferences":[],"inboundReferences":[{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"from_article\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"next-steps-for-deep-learning\"\n  }, \"Next Steps for Deep Learning\"), mdx(\"p\", null, \"src: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.quora.com/q/handsonnlpmodelreview/Deep-Learning-beyond-2019\"\n  }, \"Quora\")), mdx(\"h2\", {\n    \"id\": \"deep-learning-10\"\n  }, \"Deep Learning 1.0\"), mdx(\"p\", null, \"Limitations:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"training time/labeled data: this is a common refrain about DL/RL, in that it takes an insurmountable amount of data. Contrast this with the \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/bitter-lesson/\",\n    \"title\": \"Bitter Lesson\"\n  }, \"bitter-lesson\"), \", which claims that we \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"should\"), \" be utilising computational power.\")), mdx(\"img\", {\n    \"src\": \"https://qph.fs.quoracdn.net/main-qimg-5ff7808245cd0e86c45037f47f6244d2\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"adversarial attacks/fragility/robustness: due to the nature of DL (functional estimation), there's always going to be fault-lines.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"selection bias in training data\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"rare events/models are not able to \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"generalise\"), \", out of distribution\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"i.i.d assumption on DGP\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"temporal changes/feedback mechanisms/causal structure?\")))), mdx(\"h2\", {\n    \"id\": \"deep-learning-20\"\n  }, \"Deep Learning 2.0\"), mdx(\"h3\", {\n    \"id\": \"self-supervised-learning---learning-by-predicting-input\"\n  }, \"Self-supervised learning---learning by predicting input\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Supervised learning : this is like when a kid points to a tree and says \\\"dog!\\\", and you're like, \\\"no\\\".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Unsupervised learning : when there isn't an answer, and you're just trying to understand the data better.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"classically: clustering/pattern recognition.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"auto-encoders: pass through a bottleneck to reconstruct the input (the main question is how to develop the architecture)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"i.e. learning efficient \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"representations\")))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Semi-supervised learning : no longer just about reconstructing the input, but self-learning\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"e.g. shuffle-and-learn: shuffle video frames to figure out if it's in the correct temporal order\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"more about choosing clever objectives to optimise (to \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"learn\"), \" something intrinsic about the data)\")))), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"The brain has about 10^4 synapses and we only live for about 10^9 seconds. So we have a lot more parameters than data. This motivates the idea that we must do a lot of unsupervised learning since the perceptual input (including proprioception) is the only place we can get 10^5 dimensions of constraint per second.\")), mdx(\"p\", null, \"Hinton via \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/clyjogf/\"\n  }, \"/r/MachineLearning\"), \". \", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\"))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"much more data than \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"supervised\"), \" or #reinforcement_learning\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"if coded properly (like the shuffle-and-learn paradigm), then it can learn temporal/causal notions\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"utilisation of the agent/learner to direct things, via #attention, for instance.\")), mdx(\"img\", {\n    \"src\": \"https://qph.fs.quoracdn.net/main-qimg-e8047005bf69845ff7b2285fcd71336c\",\n    \"alt\": \"Newborns learn about gravity at 9m. Pre: experiment push car off and keep it suspended in air (with string) won't surprise. Post: surprise.\"\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"case study: BERT. self-supervised learning, predicting the next word, or missing word in sentence (reconstruction).\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"not multi-sensory/no explicit agents. this prevents it from picking up physical notions.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sure, we need multi-sensory for general-purpose intelligence, but it's still surprising how far you can go with just statistics\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"less successful in image/video (i.e. something special about words/language). \", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-2\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-2\",\n    \"className\": \"footnote-ref\"\n  }, \"2\")), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"we operate at the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"pixel\"), \"-level, which is suboptimal\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"prediction/learning in (raw) input space vs representation space\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"high-level learning should beat out raw-inputs\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-3\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-3\",\n    \"className\": \"footnote-ref\"\n  }, \"3\")))))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-{remark}\"\n  }, \"Pattern recognition $\\\\iff$ self-supervised learning?\\n\")), mdx(\"h3\", {\n    \"id\": \"leverage-power-of-compositionality-in-distributed-representations\"\n  }, \"Leverage power of compositionality in distributed representations\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"combinatorial explosion should be exploited\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"composition: basis for the intuition as to why \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"depth\"), \" in neural networks is better than \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"width\"))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-{remark}\"\n  }, \"Don't think this is a particularly interesting insight.\\n\")), mdx(\"h3\", {\n    \"id\": \"moving-away-from-stationarity\"\n  }, \"Moving away from stationarity\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"stationarity: train/test distribution is the same distribution\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"they talk about IID, which is not quite the same thing (IID is on the individual sample level---the moment you have correlations then you lose IID)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"not just following econometrics, in that the underlying distributions are time-varying though\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"feedback mechanisms (via agents/society) require dropping IID (and relate to [\", \"[fairness-project]\", \"])\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"example: classifying cows vs camels reduces to classifying desert vs grass (yellow vs green)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"not sure how this example relates, probably need to read \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/invariant-risk-minimisation/\",\n    \"title\": \"Invariant Risk Minimisation\"\n  }, \"invariant-risk-minimisation\"), \"\")))), mdx(\"h3\", {\n    \"id\": \"causality\"\n  }, \"Causality\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"causal distributed representations (causal graphs)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"allows for causal reasoning\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"it's a little like reasoning in the representation space?\")), mdx(\"h3\", {\n    \"id\": \"lifelong-learning\"\n  }, \"Lifelong Learning\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"learning-to-learn\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"cumulative learning\")), mdx(\"h3\", {\n    \"id\": \"inspiration-from-nature\"\n  }, \"Inspiration from Nature\"), mdx(\"p\", null, \"flies: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=_sOgIwyjrOA&feature=youtu.be\"\n  }, \"video\"), \"; \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://ccneuro.org/2019/proceedings/0000998.pdf\"\n  }, \"paper\")), mdx(\"p\", null, \"See \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/calculus-for-brain-computation/\",\n    \"title\": \"Calculus For Brain Computation\"\n  }, \"calculus-for-brain-computation\"), \".\"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"I'm not sure I follow the logic here. My guess is that you have a dichotomy between straight up perceptual input and actually learning by interacting with the world. But that latter feedback mechanism also contains the perceptual input, so it should be at the right scale.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-2\"\n  }, \"Could it be the fact that we deal with already highly \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"representative\"), \" objects that are already \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"classifications\"), \" of a sort, whereas everything else is at the bit/data level, and we know that's not really how we process such things. This suggests that we should find an equivalent type of \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"language\"), \"/\", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"vocabulary\"), \" for images.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-2\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-3\"\n  }, \"My feeling though is that you eventually have to go down to the raw-input space, because that is where the comparisons are made/the training is done. In other words, you can transform/encode everything into some better representation, but you'll need to decode it at some point.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-3\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/next-steps-for-deep-learning/","title":"Next Steps for Deep Learning"}}]},"tagsOutbound":{"nodes":[{"frontmatter":{"title":"","tags":["neuroscience","biologically_inspired"]},"fields":{"slug":"/calculus-for-brain-computation/","title":"Calculus For Brain Computation","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["computer_vision","biologically_inspired"]},"fields":{"slug":"/computer-vision-tasks/","title":"Computer Vision Tasks","lastUpdated":"1/22/2022","lastUpdatedAt":"2022-01-22T10:54:29.000Z","gitCreatedAt":"2022-01-22T10:54:29.000Z"}},{"frontmatter":{"title":"","tags":["neural_networks","biologically_inspired"]},"fields":{"slug":"/fast-weights/","title":"Fast Weights","lastUpdated":"2/4/2022","lastUpdatedAt":"2022-02-04T15:31:52.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","nlp","lit_review","neuroscience"]},"fields":{"slug":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/","title":"Learning as the Unsupervised Alignment of Conceptual Systems","lastUpdated":"4/16/2022","lastUpdatedAt":"2022-04-16T07:10:21.000Z","gitCreatedAt":"2022-04-15T21:18:03.000Z"}}]}},"pageContext":{"tags":["neuroscience","biologically_inspired"],"slug":"/calculus-for-brain-computation/","sidebarItems":[{"title":"","items":[{"title":"Recently Updated","url":"/latest/","collapse":true,"indent":false,"items":[{"title":"06-21: Generalisation Literature Review","url":"/generalisation-literature-review/"},{"title":"05-20: Multi-Modal Learning","url":"/multi-modal learning/"},{"title":"05-20: Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"05-10: Generalisation","url":"/generalisation/"},{"title":"05-06: Generalisation from Batch","url":"/generalisation-from-batch/"},{"title":"05-04: Fourier Features: A Curious Lens into Deep Learning","url":"/neural-paper/"},{"title":"04-27: DALL-E 2","url":"/DALL-E2/"},{"title":"04-19: World Models","url":"/world-models/"},{"title":"04-17: On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"04-16: A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"}]}]},{"title":"Tags","items":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}]}],"tagsGroups":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}],"latestPosts":[{"fields":{"slug":"/generalisation-literature-review/","title":"Generalisation Literature Review","lastUpdatedAt":"2022-06-21T17:31:53.000Z","lastUpdated":"6/21/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/multi-modal learning/","title":"Multi-Modal Learning","lastUpdatedAt":"2022-05-20T08:34:03.000Z","lastUpdated":"5/20/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/self-supervised-learning/","title":"Self-supervised Learning","lastUpdatedAt":"2022-05-20T08:21:07.000Z","lastUpdated":"5/20/2022"},"frontmatter":{"draft":false,"tags":["machine_learning"]}},{"fields":{"slug":"/generalisation/","title":"Generalisation","lastUpdatedAt":"2022-05-10T07:20:45.000Z","lastUpdated":"5/10/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/generalisation-from-batch/","title":"Generalisation from Batch","lastUpdatedAt":"2022-05-06T21:55:47.000Z","lastUpdated":"5/6/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/neural-paper/","title":"Fourier Features: A Curious Lens into Deep Learning","lastUpdatedAt":"2022-05-04T10:36:45.000Z","lastUpdated":"5/4/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/DALL-E2/","title":"DALL-E 2","lastUpdatedAt":"2022-04-27T14:31:45.000Z","lastUpdated":"4/27/2022"},"frontmatter":{"draft":false,"tags":["machine_learning","deep_learning"]}},{"fields":{"slug":"/world-models/","title":"World Models","lastUpdatedAt":"2022-04-19T16:52:41.000Z","lastUpdated":"4/19/2022"},"frontmatter":{"draft":false,"tags":["reinforcement_learning"]}},{"fields":{"slug":"/spectral-bias/","title":"On the Spectral Bias of Neural Networks","lastUpdatedAt":"2022-04-17T20:39:26.000Z","lastUpdated":"4/17/2022"},"frontmatter":{"draft":false,"tags":["from_paper"]}},{"fields":{"slug":"/a-universal-law-of-robustness-via-isoperimetry/","title":"A Universal Law of Robustness via Isoperimetry","lastUpdatedAt":"2022-04-16T07:10:21.000Z","lastUpdated":"4/16/2022"},"frontmatter":{"draft":false,"tags":["from_paper"]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}