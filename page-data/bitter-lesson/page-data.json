{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/bitter-lesson/",
    "result": {"data":{"mdx":{"id":"7216b806-4e6b-502d-89ff-1ce402e42304","tableOfContents":{"items":[{"url":"#bitter-lesson","title":"Bitter Lesson","items":[{"url":"#summary","title":"Summary"},{"url":"#thoughts","title":"Thoughts"}]}]},"fields":{"title":"Bitter Lesson","slug":"/bitter-lesson/","url":"https://deepmind.vercel.app/bitter-lesson/","editUrl":"https://github.com/dfeng/notes/tree/main/bitter-lesson.md","lastUpdatedAt":"2022-01-30T21:05:26.000Z","lastUpdated":"1/30/2022","gitCreatedAt":"2022-01-12T12:14:44.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":["from_article"],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"from_article\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"bitter-lesson\"\n  }, \"Bitter Lesson\"), mdx(\"p\", null, \"src: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://incompleteideas.net/IncIdeas/BitterLesson.html\"\n  }, \"blog\")), mdx(\"h2\", {\n    \"id\": \"summary\"\n  }, \"Summary\"), mdx(\"p\", null, \"In AI research, leveraging computation > incorporating domain knowledge. Given finite resources, it always pays to improve computation than to incorporate domain knowledge.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"the only thing that matters in the long run is the leveraging of computation\")), mdx(\"p\", null, \"This \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitter\"), \" lesson arises in part because of our anthropocentric view (that's not how we as humans solve \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"insert_difficult_task\"), \"!), biasing us towards more elaborate systems.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation.\")), mdx(\"p\", null, \"Also, there's a trade-off, especially as the injection of human knowledge gets more elaborate, then there's usually a computation cost.\"), mdx(\"h3\", {\n    \"id\": \"history\"\n  }, \"History\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Chess: search-based approaches beat out leveraging human understanding of structure of chess\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Go: key insight was \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"learning by self-play\"), \", which enabled massive computation to be brought to bear\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Speech Recognition: linguistics, we have the Unreasonable Effectiveness paper of Norvig\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"More recently, the massive scale language models (like GPT-3) show that larger models/datasets outperform fancier architectures (and history repeats itself)\")))), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.\")), mdx(\"p\", null, \"Even though a lot of our knowledge is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"guided\"), \", for most of our general-purpose intelligence, it just happens naturally, so it should be similarly for building AI.\"), mdx(\"h2\", {\n    \"id\": \"thoughts\"\n  }, \"Thoughts\"), mdx(\"p\", null, \"I'm not as familiar with the AI game literature, but at least in the context of NLP/image classification and DL, there seems to be an ideal sweet-spot in terms of finding the right kind of architecture that's powerful enough to learn, but is simple enough that you can run it on an extreme scale. I think that's partly why we still continue to innovate on the model side. If we hadn't done so, then we wouldn't have gotten \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/transformers/\",\n    \"title\": \"Transformers\"\n  }, \"transformers\"), \", which has been a boon for NLP.\"), mdx(\"p\", null, \"What is pretty clear is that domain-knowledge injection is not \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"scalable\"), \" (think expert systems back in the day). What's better are general-purpose methodologies, and the more general-purpose, the better (update: no longer think this relationship is linear: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/generalised-neural-networks/\",\n    \"title\": \"Generalized Neural Networks\"\n  }, \"generalised-neural-networks\"), \"). However, this would suggest that something like CNNs are actually \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"suboptimal\"), \", since convolutions are definitely highly specific to image classification. But I think that's part of the allure of [\", \"[graph-neural-networks]\", \"].\"), mdx(\"p\", null, \"Given the successes of CNN in image recognition, I suspect that for specific domain tasks, a little bit of domain knowledge can go a very long way (it's not like it's hard-coding edge detection, so it's still pretty general purpose).\"), mdx(\"p\", null, \"Finally, it feels like we just need to be better at \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"learning-to-learn\"), \" (\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/meta-learning/\",\n    \"title\": \"Meta Learning\"\n  }, \"meta-learning\"), \"). I don't think it's necessarily a bad thing to take inspiration from human intelligence (since we're the only successful example). So, ultimately, I think the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitter lesson\"), \" is really just a stop-gap until we can sufficiently narrow the emulation gap.\"));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\ntags:\n - from_article\n---\n\n# Bitter Lesson\n\nsrc: [blog](http://incompleteideas.net/IncIdeas/BitterLesson.html)\n\n## Summary\n\nIn AI research, leveraging computation > incorporating domain knowledge. Given finite resources, it always pays to improve computation than to incorporate domain knowledge.\n\n> the only thing that matters in the long run is the leveraging of computation\n\nThis *bitter* lesson arises in part because of our anthropocentric view (that's not how we as humans solve *insert_difficult_task*!), biasing us towards more elaborate systems.\n\n> And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation.\n\nAlso, there's a trade-off, especially as the injection of human knowledge gets more elaborate, then there's usually a computation cost.\n\n### History\n\n - Chess: search-based approaches beat out leveraging human understanding of structure of chess\n - Go: key insight was *learning by self-play*, which enabled massive computation to be brought to bear\n - Speech Recognition: linguistics, we have the Unreasonable Effectiveness paper of Norvig\n   + More recently, the massive scale language models (like GPT-3) show that larger models/datasets outperform fancier architectures (and history repeats itself)\n\n> We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.\n\nEven though a lot of our knowledge is *guided*, for most of our general-purpose intelligence, it just happens naturally, so it should be similarly for building AI.\n\n## Thoughts\n\nI'm not as familiar with the AI game literature, but at least in the context of NLP/image classification and DL, there seems to be an ideal sweet-spot in terms of finding the right kind of architecture that's powerful enough to learn, but is simple enough that you can run it on an extreme scale. I think that's partly why we still continue to innovate on the model side. If we hadn't done so, then we wouldn't have gotten [[transformers]], which has been a boon for NLP.\n\nWhat is pretty clear is that domain-knowledge injection is not *scalable* (think expert systems back in the day). What's better are general-purpose methodologies, and the more general-purpose, the better (update: no longer think this relationship is linear: [[generalised-neural-networks]]). However, this would suggest that something like CNNs are actually *suboptimal*, since convolutions are definitely highly specific to image classification. But I think that's part of the allure of [[graph-neural-networks]].\n\nGiven the successes of CNN in image recognition, I suspect that for specific domain tasks, a little bit of domain knowledge can go a very long way (it's not like it's hard-coding edge detection, so it's still pretty general purpose).\n\nFinally, it feels like we just need to be better at *learning-to-learn* (\n[[meta-learning]]). I don't think it's necessarily a bad thing to take inspiration from human intelligence (since we're the only successful example). So, ultimately, I think the *bitter lesson* is really just a stop-gap until we can sufficiently narrow the emulation gap.\n\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\n[transformers]: transformers.md \"Transformers\"\n[generalised-neural-networks]: generalised-neural-networks.md \"Generalized Neural Networks\"\n[meta-learning]: meta-learning.md \"Meta Learning\"\n[//end]: # \"Autogenerated link references\"","excerpt":"Bitter Lesson src:  blog Summary In AI research, leveraging computation > incorporating domain knowledge. Given finite resources, it always…","outboundReferences":[{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"neural_networks\", \"machine_learning\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"generalized-neural-networks\"\n  }, \"Generalized Neural Networks\"), mdx(\"p\", null, \"Recently, there has been a flurry of work that seeks to build architectures that are domain-agnostic. Perhaps unsurprisingly, most of the work in this direction uses \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/transformers/\",\n    \"title\": \"Transformers\"\n  }, \"transformers\"), \" at its core, given its (apparent) flexibility. The thesis is that domain-specific architectures work great in their particular niche, but the moment something changes, even slightly, then you're back to square one in terms of training, and square three in terms of architecture.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\")), \" Wouldn't it be great, then, to have some generic architecture that just works across all these domains?\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-2\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-2\",\n    \"className\": \"footnote-ref\"\n  }, \"2\"))), mdx(\"p\", null, \"At first blush, this seems like a no-brainer: you no longer have to build specialized architectures depending on the problem at hand, and there doesn't seem to be much downside. However, I think it's actually worthwhile to spend some time questioning this assumption.\"), mdx(\"h2\", {\n    \"id\": \"the-bad\"\n  }, \"The Bad\"), mdx(\"h3\", {\n    \"id\": \"visual-tasks\"\n  }, \"Visual Tasks\"), mdx(\"p\", null, \"Let's consider the domain of visual tasks, and in particular, the use of convolutions. While convolutions are clearly a form of inductive bias, I don't see any problem with using them as just one of several fundamental building blocks (something that cares mostly about local 2D statistics). I think stereo-pairs is a good working example here: with the current architectures, it is indeed the case that moving from single to stereo is a non-trivial architectural task that requires a choice (about how to fuse the two inputs).\"), mdx(\"p\", null, \"I also can't help but compare to how our visual system works, noting that despite our ability to handle generic visual tasks, part of the system utilizes convolutions. Granted, the fruits of evolution are not a justification in itself, but at the very least it's an existence proof that we needn't throw the baby out with the bath water on our pursuit of generalisability. And if we're going with biologically inspiration, I think stereo inputs should just be the de-facto, as that gives us the depth perception that we need to better understand the world. In terms of inputs, why not just subscribe to the inputs that we as humans have: stereo visual inputs, stereo audial inputs, and some complex input that is our nervous system.\"), mdx(\"p\", null, \"Having said all this, I realise the problem is that I'm coming at this from the perspective of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/artificial-generalised-intelligence/\",\n    \"title\": \"Artificial Generalised Intelligence\"\n  }, \"artificial-generalised-intelligence\"), \" (hence taking inspiration from how we do things). The space of inputs that machine learning covers is much wider than what we (as humans) get as inputs. That doesn't negate my argument that it makes more sense to work with a few fundamental units (instead of just one), but at least I can see why it might not be as straightforward as just following evolution.\"), mdx(\"h3\", {\n    \"id\": \"efficiency\"\n  }, \"Efficiency\"), mdx(\"p\", null, \"Convolutions are a biologically inspired, incredibly efficient means of processing image data. My guess is that the upper bound on what these kinds of generalised neural networks can achieve is to essentially reinvent the wheel and reproduce convolutions. And perhaps future models are flexible enough to do that. For now, though, the best we can hope for is to achieve some sort of parity in performance, though at the (terrible) expense of efficiency and compute. Granted, I do think visual tasks are an easy target, since there already is a simple, obvious architecture which gets you very far. I'm less familiar with the audio world.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-3\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-3\",\n    \"className\": \"footnote-ref\"\n  }, \"3\"))), mdx(\"h3\", {\n    \"id\": \"great-power-great-responsibility\"\n  }, \"Great Power, Great Responsibility\"), mdx(\"p\", null, \"Letting the data speak for itself comes with its own problems (and we're not even talking about the [\", \"[fairness-project]\", \"]). At a high level, this is similar to the problem of [\", \"[reinforcement-learning]\", \"] (paperclip): given a sufficiently powerful generic algorithm, it will find ways to achieve the goal assigned to it that are possibly counter to what we would like it to learn. That is, it will pick up on correlations and use those, operating under the assumption that correlation implies causation ([\", \"[causal-inference]\", \"]). A simple example is, when classifying a boat, a generic algorithm will use the whole image (e.g. presence of the sea) to help it to classify, maybe to the point where it doesn't even care about the specifics of the target object (see also \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/computer-vision-tasks/\",\n    \"title\": \"Computer Vision Tasks\"\n  }, \"computer-vision-tasks\"), \").\"), mdx(\"p\", null, \"In some sense, with these kinds of generalised architectures, the inductive bias step is now hidden in the regularisation techniques. Now, it's probable that regularisation is actually where you want to inject these kinds of biases (as opposed to in the architecture). Again with relating it to humans, our generalised intelligence doesn't have the same kinds of problem, a simple reason being that our learnings are not the result of some simple loss function. That is, it's the fact that we're doing a \\\"simple\\\" non-convex optimization that leads to these kinds of quirky solutions.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-4\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-4\",\n    \"className\": \"footnote-ref\"\n  }, \"4\"))), mdx(\"h2\", {\n    \"id\": \"the-good\"\n  }, \"The Good?\"), mdx(\"p\", null, \"When such generic architectures actually succeed, it provides fairly strong evidence that this particular architecture is a powerful fundamental building block, and perhaps should be used in the later layers of a generalised neural network. On the other hand, it's \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"almost\"), \" akin to saying that \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"NOT\"), \" gates are a powerful building block for computers \\u2013 how much do we learn from such a statement in terms of understanding how computers work?\"), mdx(\"p\", null, \"Being domain-agnostic seems like it would be\\nMeanwhile, being input/output format agnostic lets you experiment with combining different input sources \"), mdx(\"p\", null, \"It also speaks in part to the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/bitter-lesson/\",\n    \"title\": \"Bitter Lesson\"\n  }, \"bitter-lesson\"), \". However, I think the regime here is a little different: there are \"), mdx(\"h2\", {\n    \"id\": \"literature\"\n  }, \"Literature\"), mdx(\"h3\", {\n    \"id\": \"perceiver\"\n  }, \"Perceiver\"), mdx(\"p\", null, \"src: \", \"(Jaegle et al., 2021)\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-jaegle2021perceiver\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-jaegle2021perceiver\",\n    \"className\": \"footnote-ref\"\n  }, \"jaegle2021perceiver\"))), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"A simple example is going from single images to stereo pairs, akin to how our own visual system works.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-2\"\n  }, \"In the words of LeCun, let the data speak for itself.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-2\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-3\"\n  }, \"Though in my brief stint, I remember that convolutions (just 1D) also played a role.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-3\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-4\"\n  }, \"And if you think about it, no amount of injecting common-sense could really sidestep this fundamental flaw.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-4\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-jaegle2021perceiver\"\n  }, \"Jaegle, A. et al., 2021. Perceiver: General Perception with Iterative Attention,\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-jaegle2021perceiver\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/generalised-neural-networks/","title":"Generalized Neural Networks","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"machine_learning\", \"meta_learning\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"meta-learning\"\n  }, \"Meta Learning\"), mdx(\"p\", null, \"src: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-105.pdf\"\n  }, \"thesis\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"relates to [\", \"[transfer-learning]\", \"], except you're trying to do an even better kind of pre-training, that generalises across all tasks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"intuition:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"you want to train a NN so that it does well on a whole class of tasks, and not specific to one dataset\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"you want to \\\"pre-train\\\" a NN such that, regardless of the task you eventually train it on, it'll be very quick to \\\"train\\\"\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"speed of training is a proxy for \\\"close-ness\\\" of the solution\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"if you're learning a useful representation, then this pre-trained model should speed up training\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"mark\", null, \"it seems to me that this doesn't necessarily hold: if you think of training a NN as \\\"learning\\\", then this is like starting with knowledge of \\\"fundamentals\\\". but I don't think the analogy works very well, since it's really just the \\\"initialisation\\\", and it quickly gets \\\"replaced\\\".\"), \"- I guess what I'd like is some kind of **augmentation** - a little more like how LSTMs have a memory slot\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"then they're going to use gradient updates, somehow\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"my initial guess:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"suppose you have a set of datasets. in some sense, what you want is to find the mid-point of all the trained models. you could just take one step per dataset (or sampled)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"but will this \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"converge\"), \"?\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"it might be the case that the steps you take are in the opposite direction?\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"though, if that's the case then that just means you've reached an \\\"impasse\\\" (or that there's nothing shared between them)\"))))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"The process of training a model\\u2019s parameters such that a few gradient steps, or even a single gradient step, can produce good results on a new task can be viewed from a feature learning standpoint as building an internal representation that is broadly suitable for many tasks.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"em\", {\n    parentName: \"li\"\n  }, \"From a dynamical systems standpoint, our learning process can be viewed as maximising the sensitivity of the loss functions of new tasks with respect to the parameters\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"they have some theory that shows that a single gradient-step can get you to any function (??) \\u2013 this seems impossible\")));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/meta-learning/","title":"Meta Learning","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"machine_learning\", \"neural_networks\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"transformers\"\n  }, \"Transformers\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"references:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html\"\n  }, \"lil-log\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://distill.pub/2016/augmented-rnns/\"\n  }, \"distill\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://d2l.ai/chapter_attention-mechanisms/transformer.html\"\n  }, \"ebook-chapter\"), \" on transformers (actually this ebook isn't great, as it ends up being more about the implementation)\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"it turns out that #attention is an earlier concept, which itself is motivated by the encoder-decoder sequence-to-sequence architecture\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"img\", {\n    parentName: \"li\",\n    \"src\": \"https://karpathy.github.io/assets/rnn/diags.jpeg\",\n    \"alt\": null\n  })), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"(oops) I didn't really understand this diagram:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sequence to sequence models are essentially the third diagram, where basically the input sequence and output sequence are asynchronous\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"versus the normal rnn, which takes the output as the input\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"I really like the example of 1-to-many, image-to-caption, so your input is not a sequence, but your output is\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"seq2seq example is the translation program, where importantly the input and output sequence don't have to be the same length (due to the way languages differ in their realisations of the same meaning)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"the encoder is the rnn on the input sequence, and this culminates into the last hidden layer\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"this is essentially the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"context\"), \" vector: the idea here is that this (fixed-length) vector captures all the information about the sentence\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"key: this acts like a sort of \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"informational bottleneck\"), \", and actually is the impetus for the attention mechanic\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"key point (via this \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1703.01619.pdf\"\n  }, \"tutorial\"), \"):\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"instead of having everything represented as the last hidden layer (fixed-length), why not just look at all the hidden layers (vectors representing each word)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"but, that would be \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"variable\"), \" length, so instead just look at a linear combination of those hidden layers. this linear combination is learned, and is basically \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"attention\")))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Transformers #todo\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"prior art\\\"\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"CNN: easy to parallelise, but aren't recurrent (can't capture sequential dependency)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RNN: reverse\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"goal of transformers/attention is achieve \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"parallelization\"), \" and \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"recurrence\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"by appealing to \\\"attention\\\" to get the recurrence (?)\")))))), mdx(\"h2\", {\n    \"id\": \"transformers-1\"\n  }, \"Transformers\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"key is \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"multi-head self-attention\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"encoded representation of input: key-value pairs (\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"K\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"separator\": \"true\"\n  }, \",\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"V\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2208\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\",\n    \"mathvariant\": \"double-struck\"\n  }, \"R\"), mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"n\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"K,V \\\\in \\\\mathbb{R}^{n}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8777699999999999em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.07153em\"\n    }\n  }, \"K\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mpunct\"\n  }, \",\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.22222em\"\n    }\n  }, \"V\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"\\u2208\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68889em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathbb\"\n  }, \"R\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.664392em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"n\"))))))))))))), \")\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"corresponding to hidden states\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"previous output is compressed into query \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"Q\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2208\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\",\n    \"mathvariant\": \"double-struck\"\n  }, \"R\"), mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"m\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"Q \\\\in \\\\mathbb{R}^{m}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8777699999999999em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"Q\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"\\u2208\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68889em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathbb\"\n  }, \"R\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.664392em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"m\"))))))))))))), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"output of the transformer is a weighted sum of the values (\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"V\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"V\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68333em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.22222em\"\n    }\n  }, \"V\"))))), \").\")))), mdx(\"h2\", {\n    \"id\": \"todo\"\n  }, \"Todo\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Visualising and Measuring the Geometry of BERT \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1906.02715.pdf\"\n  }, \"arXiv\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.peterbloem.nl/blog/transformers\"\n  }, \"random blog\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"pretty intuitive description of transformers on \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://nostalgebraist.tumblr.com/post/185326092369/the-transformer-explained\"\n  }, \"tumblr\"), \", via the LessWrong community\")));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/transformers/","title":"Transformers","shouldShowTitle":false}}],"inboundReferences":[{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"neural_networks\", \"machine_learning\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"generalized-neural-networks\"\n  }, \"Generalized Neural Networks\"), mdx(\"p\", null, \"Recently, there has been a flurry of work that seeks to build architectures that are domain-agnostic. Perhaps unsurprisingly, most of the work in this direction uses \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/transformers/\",\n    \"title\": \"Transformers\"\n  }, \"transformers\"), \" at its core, given its (apparent) flexibility. The thesis is that domain-specific architectures work great in their particular niche, but the moment something changes, even slightly, then you're back to square one in terms of training, and square three in terms of architecture.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\")), \" Wouldn't it be great, then, to have some generic architecture that just works across all these domains?\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-2\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-2\",\n    \"className\": \"footnote-ref\"\n  }, \"2\"))), mdx(\"p\", null, \"At first blush, this seems like a no-brainer: you no longer have to build specialized architectures depending on the problem at hand, and there doesn't seem to be much downside. However, I think it's actually worthwhile to spend some time questioning this assumption.\"), mdx(\"h2\", {\n    \"id\": \"the-bad\"\n  }, \"The Bad\"), mdx(\"h3\", {\n    \"id\": \"visual-tasks\"\n  }, \"Visual Tasks\"), mdx(\"p\", null, \"Let's consider the domain of visual tasks, and in particular, the use of convolutions. While convolutions are clearly a form of inductive bias, I don't see any problem with using them as just one of several fundamental building blocks (something that cares mostly about local 2D statistics). I think stereo-pairs is a good working example here: with the current architectures, it is indeed the case that moving from single to stereo is a non-trivial architectural task that requires a choice (about how to fuse the two inputs).\"), mdx(\"p\", null, \"I also can't help but compare to how our visual system works, noting that despite our ability to handle generic visual tasks, part of the system utilizes convolutions. Granted, the fruits of evolution are not a justification in itself, but at the very least it's an existence proof that we needn't throw the baby out with the bath water on our pursuit of generalisability. And if we're going with biologically inspiration, I think stereo inputs should just be the de-facto, as that gives us the depth perception that we need to better understand the world. In terms of inputs, why not just subscribe to the inputs that we as humans have: stereo visual inputs, stereo audial inputs, and some complex input that is our nervous system.\"), mdx(\"p\", null, \"Having said all this, I realise the problem is that I'm coming at this from the perspective of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/artificial-generalised-intelligence/\",\n    \"title\": \"Artificial Generalised Intelligence\"\n  }, \"artificial-generalised-intelligence\"), \" (hence taking inspiration from how we do things). The space of inputs that machine learning covers is much wider than what we (as humans) get as inputs. That doesn't negate my argument that it makes more sense to work with a few fundamental units (instead of just one), but at least I can see why it might not be as straightforward as just following evolution.\"), mdx(\"h3\", {\n    \"id\": \"efficiency\"\n  }, \"Efficiency\"), mdx(\"p\", null, \"Convolutions are a biologically inspired, incredibly efficient means of processing image data. My guess is that the upper bound on what these kinds of generalised neural networks can achieve is to essentially reinvent the wheel and reproduce convolutions. And perhaps future models are flexible enough to do that. For now, though, the best we can hope for is to achieve some sort of parity in performance, though at the (terrible) expense of efficiency and compute. Granted, I do think visual tasks are an easy target, since there already is a simple, obvious architecture which gets you very far. I'm less familiar with the audio world.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-3\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-3\",\n    \"className\": \"footnote-ref\"\n  }, \"3\"))), mdx(\"h3\", {\n    \"id\": \"great-power-great-responsibility\"\n  }, \"Great Power, Great Responsibility\"), mdx(\"p\", null, \"Letting the data speak for itself comes with its own problems (and we're not even talking about the [\", \"[fairness-project]\", \"]). At a high level, this is similar to the problem of [\", \"[reinforcement-learning]\", \"] (paperclip): given a sufficiently powerful generic algorithm, it will find ways to achieve the goal assigned to it that are possibly counter to what we would like it to learn. That is, it will pick up on correlations and use those, operating under the assumption that correlation implies causation ([\", \"[causal-inference]\", \"]). A simple example is, when classifying a boat, a generic algorithm will use the whole image (e.g. presence of the sea) to help it to classify, maybe to the point where it doesn't even care about the specifics of the target object (see also \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/computer-vision-tasks/\",\n    \"title\": \"Computer Vision Tasks\"\n  }, \"computer-vision-tasks\"), \").\"), mdx(\"p\", null, \"In some sense, with these kinds of generalised architectures, the inductive bias step is now hidden in the regularisation techniques. Now, it's probable that regularisation is actually where you want to inject these kinds of biases (as opposed to in the architecture). Again with relating it to humans, our generalised intelligence doesn't have the same kinds of problem, a simple reason being that our learnings are not the result of some simple loss function. That is, it's the fact that we're doing a \\\"simple\\\" non-convex optimization that leads to these kinds of quirky solutions.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-4\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-4\",\n    \"className\": \"footnote-ref\"\n  }, \"4\"))), mdx(\"h2\", {\n    \"id\": \"the-good\"\n  }, \"The Good?\"), mdx(\"p\", null, \"When such generic architectures actually succeed, it provides fairly strong evidence that this particular architecture is a powerful fundamental building block, and perhaps should be used in the later layers of a generalised neural network. On the other hand, it's \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"almost\"), \" akin to saying that \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"NOT\"), \" gates are a powerful building block for computers \\u2013 how much do we learn from such a statement in terms of understanding how computers work?\"), mdx(\"p\", null, \"Being domain-agnostic seems like it would be\\nMeanwhile, being input/output format agnostic lets you experiment with combining different input sources \"), mdx(\"p\", null, \"It also speaks in part to the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/bitter-lesson/\",\n    \"title\": \"Bitter Lesson\"\n  }, \"bitter-lesson\"), \". However, I think the regime here is a little different: there are \"), mdx(\"h2\", {\n    \"id\": \"literature\"\n  }, \"Literature\"), mdx(\"h3\", {\n    \"id\": \"perceiver\"\n  }, \"Perceiver\"), mdx(\"p\", null, \"src: \", \"(Jaegle et al., 2021)\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-jaegle2021perceiver\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-jaegle2021perceiver\",\n    \"className\": \"footnote-ref\"\n  }, \"jaegle2021perceiver\"))), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"A simple example is going from single images to stereo pairs, akin to how our own visual system works.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-2\"\n  }, \"In the words of LeCun, let the data speak for itself.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-2\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-3\"\n  }, \"Though in my brief stint, I remember that convolutions (just 1D) also played a role.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-3\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-4\"\n  }, \"And if you think about it, no amount of injecting common-sense could really sidestep this fundamental flaw.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-4\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-jaegle2021perceiver\"\n  }, \"Jaegle, A. et al., 2021. Perceiver: General Perception with Iterative Attention,\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-jaegle2021perceiver\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/generalised-neural-networks/","title":"Generalized Neural Networks"}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"from_article\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"next-steps-for-deep-learning\"\n  }, \"Next Steps for Deep Learning\"), mdx(\"p\", null, \"src: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.quora.com/q/handsonnlpmodelreview/Deep-Learning-beyond-2019\"\n  }, \"Quora\")), mdx(\"h2\", {\n    \"id\": \"deep-learning-10\"\n  }, \"Deep Learning 1.0\"), mdx(\"p\", null, \"Limitations:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"training time/labeled data: this is a common refrain about DL/RL, in that it takes an insurmountable amount of data. Contrast this with the \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/bitter-lesson/\",\n    \"title\": \"Bitter Lesson\"\n  }, \"bitter-lesson\"), \", which claims that we \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"should\"), \" be utilising computational power.\")), mdx(\"img\", {\n    \"src\": \"https://qph.fs.quoracdn.net/main-qimg-5ff7808245cd0e86c45037f47f6244d2\",\n    \"alt\": null\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"adversarial attacks/fragility/robustness: due to the nature of DL (functional estimation), there's always going to be fault-lines.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"selection bias in training data\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"rare events/models are not able to \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"generalise\"), \", out of distribution\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"i.i.d assumption on DGP\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"temporal changes/feedback mechanisms/causal structure?\")))), mdx(\"h2\", {\n    \"id\": \"deep-learning-20\"\n  }, \"Deep Learning 2.0\"), mdx(\"h3\", {\n    \"id\": \"self-supervised-learning---learning-by-predicting-input\"\n  }, \"Self-supervised learning---learning by predicting input\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Supervised learning : this is like when a kid points to a tree and says \\\"dog!\\\", and you're like, \\\"no\\\".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Unsupervised learning : when there isn't an answer, and you're just trying to understand the data better.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"classically: clustering/pattern recognition.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"auto-encoders: pass through a bottleneck to reconstruct the input (the main question is how to develop the architecture)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"i.e. learning efficient \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"representations\")))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Semi-supervised learning : no longer just about reconstructing the input, but self-learning\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"e.g. shuffle-and-learn: shuffle video frames to figure out if it's in the correct temporal order\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"more about choosing clever objectives to optimise (to \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"learn\"), \" something intrinsic about the data)\")))), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"The brain has about 10^4 synapses and we only live for about 10^9 seconds. So we have a lot more parameters than data. This motivates the idea that we must do a lot of unsupervised learning since the perceptual input (including proprioception) is the only place we can get 10^5 dimensions of constraint per second.\")), mdx(\"p\", null, \"Hinton via \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/clyjogf/\"\n  }, \"/r/MachineLearning\"), \". \", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\"))), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"much more data than \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"supervised\"), \" or #reinforcement_learning\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"if coded properly (like the shuffle-and-learn paradigm), then it can learn temporal/causal notions\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"utilisation of the agent/learner to direct things, via #attention, for instance.\")), mdx(\"img\", {\n    \"src\": \"https://qph.fs.quoracdn.net/main-qimg-e8047005bf69845ff7b2285fcd71336c\",\n    \"alt\": \"Newborns learn about gravity at 9m. Pre: experiment push car off and keep it suspended in air (with string) won't surprise. Post: surprise.\"\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"case study: BERT. self-supervised learning, predicting the next word, or missing word in sentence (reconstruction).\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"not multi-sensory/no explicit agents. this prevents it from picking up physical notions.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sure, we need multi-sensory for general-purpose intelligence, but it's still surprising how far you can go with just statistics\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"less successful in image/video (i.e. something special about words/language). \", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-2\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-2\",\n    \"className\": \"footnote-ref\"\n  }, \"2\")), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"we operate at the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"pixel\"), \"-level, which is suboptimal\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"prediction/learning in (raw) input space vs representation space\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"high-level learning should beat out raw-inputs\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-3\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-3\",\n    \"className\": \"footnote-ref\"\n  }, \"3\")))))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-{remark}\"\n  }, \"Pattern recognition $\\\\iff$ self-supervised learning?\\n\")), mdx(\"h3\", {\n    \"id\": \"leverage-power-of-compositionality-in-distributed-representations\"\n  }, \"Leverage power of compositionality in distributed representations\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"combinatorial explosion should be exploited\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"composition: basis for the intuition as to why \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"depth\"), \" in neural networks is better than \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"width\"))), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-{remark}\"\n  }, \"Don't think this is a particularly interesting insight.\\n\")), mdx(\"h3\", {\n    \"id\": \"moving-away-from-stationarity\"\n  }, \"Moving away from stationarity\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"stationarity: train/test distribution is the same distribution\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"they talk about IID, which is not quite the same thing (IID is on the individual sample level---the moment you have correlations then you lose IID)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"not just following econometrics, in that the underlying distributions are time-varying though\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"feedback mechanisms (via agents/society) require dropping IID (and relate to [\", \"[fairness-project]\", \"])\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"example: classifying cows vs camels reduces to classifying desert vs grass (yellow vs green)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"not sure how this example relates, probably need to read \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/invariant-risk-minimisation/\",\n    \"title\": \"Invariant Risk Minimisation\"\n  }, \"invariant-risk-minimisation\"), \"\")))), mdx(\"h3\", {\n    \"id\": \"causality\"\n  }, \"Causality\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"causal distributed representations (causal graphs)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"allows for causal reasoning\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"it's a little like reasoning in the representation space?\")), mdx(\"h3\", {\n    \"id\": \"lifelong-learning\"\n  }, \"Lifelong Learning\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"learning-to-learn\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"cumulative learning\")), mdx(\"h3\", {\n    \"id\": \"inspiration-from-nature\"\n  }, \"Inspiration from Nature\"), mdx(\"p\", null, \"flies: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=_sOgIwyjrOA&feature=youtu.be\"\n  }, \"video\"), \"; \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://ccneuro.org/2019/proceedings/0000998.pdf\"\n  }, \"paper\")), mdx(\"p\", null, \"See \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/calculus-for-brain-computation/\",\n    \"title\": \"Calculus For Brain Computation\"\n  }, \"calculus-for-brain-computation\"), \".\"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"I'm not sure I follow the logic here. My guess is that you have a dichotomy between straight up perceptual input and actually learning by interacting with the world. But that latter feedback mechanism also contains the perceptual input, so it should be at the right scale.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-2\"\n  }, \"Could it be the fact that we deal with already highly \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"representative\"), \" objects that are already \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"classifications\"), \" of a sort, whereas everything else is at the bit/data level, and we know that's not really how we process such things. This suggests that we should find an equivalent type of \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"language\"), \"/\", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"vocabulary\"), \" for images.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-2\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-3\"\n  }, \"My feeling though is that you eventually have to go down to the raw-input space, because that is where the comparisons are made/the training is done. In other words, you can transform/encode everything into some better representation, but you'll need to decode it at some point.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-3\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/next-steps-for-deep-learning/","title":"Next Steps for Deep Learning"}}]},"tagsOutbound":{"nodes":[{"frontmatter":{"title":"","tags":["from_article"]},"fields":{"slug":"/bitter-lesson/","title":"Bitter Lesson","lastUpdated":"1/30/2022","lastUpdatedAt":"2022-01-30T21:05:26.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["from_article","nlp"]},"fields":{"slug":"/explaining-word-embeddings/","title":"Explaining Word Embeddings","lastUpdated":"2/13/2022","lastUpdatedAt":"2022-02-13T17:46:16.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["from_article","neural_networks","graph_neural_networks"]},"fields":{"slug":"/graph-network-as-arbitrary-inductive-bias/","title":"Graph Network as Arbitrary Inductive Bias","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["economics","from_article"]},"fields":{"slug":"/market-for-lemons/","title":"Market for Lemons","lastUpdated":"1/4/2022","lastUpdatedAt":"2022-01-04T21:27:53.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["from_article"]},"fields":{"slug":"/next-steps-for-deep-learning/","title":"Next Steps for Deep Learning","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}}]}},"pageContext":{"tags":["from_article"],"slug":"/bitter-lesson/","sidebarItems":[{"title":"","items":[{"title":"Recently Updated","url":"/latest/","collapse":true,"indent":false,"items":[{"title":"07-04: Text Recognition","url":"/text-recognition/"},{"title":"07-04: CNNs","url":"/convolutional-neural-networks/"},{"title":"06-27: Generalisation Literature Review","url":"/generalisation-literature-review/"},{"title":"05-20: Multi-Modal Learning","url":"/multi-modal learning/"},{"title":"05-20: Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"05-10: Generalisation","url":"/generalisation/"},{"title":"05-06: Generalisation from Batch","url":"/generalisation-from-batch/"},{"title":"05-04: Fourier Features: A Curious Lens into Deep Learning","url":"/neural-paper/"},{"title":"04-27: DALL-E 2","url":"/DALL-E2/"},{"title":"04-19: World Models","url":"/world-models/"}]}]},{"title":"Tags","items":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}]}],"tagsGroups":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}],"latestPosts":[{"fields":{"slug":"/text-recognition/","title":"Text Recognition","lastUpdatedAt":"2022-07-04T14:45:00.000Z","lastUpdated":"7/4/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/convolutional-neural-networks/","title":"CNNs","lastUpdatedAt":"2022-07-04T13:36:29.000Z","lastUpdated":"7/4/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/generalisation-literature-review/","title":"Generalisation Literature Review","lastUpdatedAt":"2022-06-27T15:06:07.000Z","lastUpdated":"6/27/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/multi-modal learning/","title":"Multi-Modal Learning","lastUpdatedAt":"2022-05-20T08:34:03.000Z","lastUpdated":"5/20/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/self-supervised-learning/","title":"Self-supervised Learning","lastUpdatedAt":"2022-05-20T08:21:07.000Z","lastUpdated":"5/20/2022"},"frontmatter":{"draft":false,"tags":["machine_learning"]}},{"fields":{"slug":"/generalisation/","title":"Generalisation","lastUpdatedAt":"2022-05-10T07:20:45.000Z","lastUpdated":"5/10/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/generalisation-from-batch/","title":"Generalisation from Batch","lastUpdatedAt":"2022-05-06T21:55:47.000Z","lastUpdated":"5/6/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/neural-paper/","title":"Fourier Features: A Curious Lens into Deep Learning","lastUpdatedAt":"2022-05-04T10:36:45.000Z","lastUpdated":"5/4/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/DALL-E2/","title":"DALL-E 2","lastUpdatedAt":"2022-04-27T14:31:45.000Z","lastUpdated":"4/27/2022"},"frontmatter":{"draft":false,"tags":["machine_learning","deep_learning"]}},{"fields":{"slug":"/world-models/","title":"World Models","lastUpdatedAt":"2022-04-19T16:52:41.000Z","lastUpdated":"4/19/2022"},"frontmatter":{"draft":false,"tags":["reinforcement_learning"]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}