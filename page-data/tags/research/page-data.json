{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-tag-query-js",
    "path": "/tags/research/",
    "result": {"data":{"site":{"pathPrefix":"","siteMetadata":{"siteUrl":"https://deepmind.vercel.app"}},"allMdx":{"nodes":[{"frontmatter":{"title":"","draft":false},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"networks\", \"research\", \"statistics\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"dynamic-graph-models\"\n  }, \"Dynamic Graph Models\"), mdx(\"p\", null, \"The traditional way of thinking about networks is to treat them as essentially fixed, and samples from some generative model. Of course, we all know that networks don't just spontaneously appear. That being said, a) collecting the entire history of a network's evolution to its current state is often impossible, and b) dynamic models introduce too many more degrees of modelling freedom, so the purists generally shy away from it.\"), mdx(\"p\", null, \"A useful dynamic model is one where the dynamics is fairly simple, and yet interesting global features still manifest themselves (in the spirit of [\", \"[complexity-theory]\", \"]). The classic example of this is the Preferential Attachment (PA) model, which, by a very simple \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"rich-get-richer\"), \" adjustment to the Uniform Attachment (UA) model creates a power-law degree distribution. A simple description of these models is, at each time step \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"t\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"t\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.61508em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"t\"))))), \", we introduce a new vertex \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"v\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"t\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"v_t\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.58056em\",\n      \"verticalAlign\": \"-0.15em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"v\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.2805559999999999em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"-0.03588em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"t\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))))))), \", and we add \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"m\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"m\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.43056em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"m\"))))), \" new edges from this new one.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\")), \" The probability that an existing vertex has an edge to this vertex is either uniform (UA), or weighted by its current degree (PA),\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-2\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-2\",\n    \"className\": \"footnote-ref\"\n  }, \"2\"))), mdx(\"div\", {\n    \"className\": \"math math-display\"\n  }, mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"katex-display\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\",\n    \"display\": \"block\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"P\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \"(\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"A\"), mdx(\"mrow\", {\n    parentName: \"msub\"\n  }, mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"v\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"t\")), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"separator\": \"true\"\n  }, \",\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"v\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"i\")))), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \")\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"mfrac\", {\n    parentName: \"mrow\"\n  }, mdx(\"msub\", {\n    parentName: \"mfrac\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"d\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"i\")), mdx(\"mrow\", {\n    parentName: \"mfrac\"\n  }, mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2211\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"d\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"i\")))), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"separator\": \"true\"\n  }, \",\"), mdx(\"mspace\", {\n    parentName: \"mrow\",\n    \"width\": \"1em\"\n  }), mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"normal\"\n  }, \"\\u2200\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"i\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2208\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"E\"), mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"normal\"\n  }, \".\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"P(A_{v_t, v_i}) = \\\\frac{d_i}{\\\\sum d_i}, \\\\quad \\\\forall i \\\\in E.\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1.036108em\",\n      \"verticalAlign\": \"-0.286108em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"P\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"A\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15139200000000003em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"0em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"v\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.29634285714285713em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.357em\",\n      \"marginLeft\": \"-0.03588em\",\n      \"marginRight\": \"0.07142857142857144em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.5em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size3 size1 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"t\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.143em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mpunct mtight\"\n  }, \",\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"v\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.3280857142857143em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.357em\",\n      \"marginLeft\": \"-0.03588em\",\n      \"marginRight\": \"0.07142857142857144em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.5em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size3 size1 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"i\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.143em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.286108em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose\"\n  }, \")\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"2.3074500000000002em\",\n      \"verticalAlign\": \"-0.93601em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen nulldelimiter\"\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mfrac\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"1.37144em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.314em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mop op-symbol small-op\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"top\": \"-0.0000050000000000050004em\"\n    }\n  }, \"\\u2211\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"d\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.31166399999999994em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"0em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"i\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.23em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"frac-line\",\n    \"style\": {\n      \"borderBottomWidth\": \"0.04em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.677em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"d\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.31166399999999994em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"0em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"i\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  }))))))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.93601em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  }))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose nulldelimiter\"\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mpunct\"\n  }, \",\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"1em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"\\u2200\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"i\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"\\u2208\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68333em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.05764em\"\n    }\n  }, \"E\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \".\")))))), mdx(\"p\", null, \"Thanks to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://blogs.princeton.edu/imabandit/2014/03/30/on-the-influence-of-the-seed-graph-in-the-preferential-attachment-model/\"\n  }, \"Bubeck\"), \", a completely different view of PA models is to focus on the temporal/growth aspect of it -- by their very dynamics, we unlock a slew of different questions to ask. At a high level, the questions revolve around how much temporal information is recoverable from the final state?\"), mdx(\"p\", null, \"For instance, we might be interested in determining the \\\"seed\\\" of a network\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-3\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-3\",\n    \"className\": \"footnote-ref\"\n  }, \"3\")), \", e.g. to figure out the early core of the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"internet\"), \". In the case of a pandemic, reverse-engineering the infection/contact network might give insight into the early actors. Of course, no real-life network follows a PA model exactly, which leads to the more practical question of, how much temporal information is recoverable even under a corrupted model?\"), mdx(\"p\", null, \"A simple corruption is to simply inject random edges (sort of like having an ER graph embedded in the graph) -- the opposite being having missing data (or both!). There's probably an asymmetry here: adding edges makes retrieval more difficult than deleting edges. A simple extreme example: in the PA model with \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"m\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"mn\", {\n    parentName: \"mrow\"\n  }, \"1\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"m=1\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.43056em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"m\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.64444em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"1\"))))), \", the resulting graph is always a tree, which remains true when deleting but not when adding at random. Thus, any algorithm that relies on the tree breaks down.\"), mdx(\"h2\", {\n    \"id\": \"existing-work\"\n  }, \"Existing Work\"), mdx(\"p\", null, \"The first problem (via this \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://blogs.princeton.edu/imabandit/2017/01/01/guest-post-by-miklos-racz-confidence-sets-for-the-root-in-uniform-and-preferential-attachment-trees/\"\n  }, \"blog-post\"), \") involves asking questions about the seed graph (or the root). In a nutshell, the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"centroid\"), \" of a tree, which is defined as the vertex whose removal results in the minimum largest component, is actually a good estimate of the root. Proving such a statement utilises the probabilist's favourite home appliance, the Polya Urn.\"), mdx(\"img\", {\n    \"src\": \"https://blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2017/01/polya_blog-768x459.png\",\n    \"alt\": \"The Centroid (1)\"\n  }), mdx(\"p\", null, \"A similar problem (older \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://blogs.princeton.edu/imabandit/2014/03/30/on-the-influence-of-the-seed-graph-in-the-preferential-attachment-model/\"\n  }, \"blog-post\"), \") looks at the question of whether or not the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"seed\"), \" graph has any influence (in the limit). Formally, we consider if the total variation distance between the two limiting distributions of two different seeds is bounded away from zero. This is a weaker requirement, since being able to recover the seed implies it has influence.\"), mdx(\"p\", null, \"This line of inquiry can also be framed as follows: if we think about social networks, then what you might be interested in is this notion of the early-bird advantage \\u2013 just by being there early, you get outsized returns (degree). Suppose people enter a network with the object of maximising that return. Then it almost becomes something like a multilevel marketing (pyramid) scheme.\"), mdx(\"h2\", {\n    \"id\": \"open-problems\"\n  }, \"Open Problems\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Our intuition tells us that the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"network effect\"), \" is definitely something that advantages people who are earlier to a platform. In a very similar vein to the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"rich-get-richer\"), \" scheme, being early is essentially synonymous with being rich. However, it needn't be that way. I think it might be useful to try to come up with a model that is essentially arrival-time agnostic, i.e. you have exchangeability at the node-level, which is something you generally get for free when you're doing generative static network models, but is explicitly unavailable for dynamic models. Having such a model might help us elucidate the structural differences between two scale-free, dynamic models that differ on that one point.\")), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"i.e. each vertex has out-degree \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"m\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"m\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.43056em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"m\"))))), \".\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-2\"\n  }, \"Something that I only just realised after reading the wiki entry on the BA model is that they frame it thusly: you need both PA and growth for there to be scale-free structure, where growth simply means that the size of the network is growing.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-2\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-3\"\n  }, \"You can adjust the model by starting with a fixed seed network (instead of a single node).\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-3\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/dynamic-graph-models/","title":"Dynamic Graph Models","lastUpdated":"4/16/2022","lastUpdatedAt":"2022-04-16T07:10:21.000Z","gitCreatedAt":"2022-04-15T20:31:09.000Z"}},{"frontmatter":{"title":"","draft":false},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"from_paper\", \"society\", \"research\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"stewardship-of-global-collective-behaviour\"\n  }, \"Stewardship of Global Collective Behaviour\"), mdx(\"p\", null, \"src: \", \"(Bak-Coleman et al., 2021)\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-BakColeman:2021wt\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-BakColeman:2021wt\",\n    \"className\": \"footnote-ref\"\n  }, \"BakColeman:2021wt\"))), mdx(\"p\", null, \"A well written call-to-arms for some sort of interdisciplinary effort to understand the possible pernicious effects of social media and more broadly the rapid pace of technological change affecting the way we communicate, form groups, digest information, and hopefully provide guidance on how to solve these problems (e.g. writing pieces specifically for regulators).\"), mdx(\"p\", null, \"They use a term called \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"crisis discipline\"), \" which I like, the canonical example being climate (change) science: you have this incredibly complicated system that needs urgent research and attention (for catastrophic reasons), but you don't necessarily have the time (or it's just not possible given the complexities of the system) to be entirely systematic and sure about the conclusions. In other words, these kinds of disciplines call for a much more \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"agile\"), \" form of research.\"), mdx(\"p\", null, \"What's interesting to me is that they couch all this talk through the lens of [\", \"[complexity-theory]\", \"]. The idea is that, for instance, once you connect half the world's population together through the internet, or social media, you're going to get unaccounted-for emergent behaviour, very much like those studied in complexity science, except usually the subject is natural processes (like swarms of locusts or school of fish). The difference now is that we're dealing with humans, social interactions.\"), mdx(\"p\", null, \"A good example here is the flow of information. Usually when we think of information flow we think of communication networks, where we're sending bits of data around. However, the real information flow networks, and those that matter the most right now from a catastrophic perspective, are the information flows that we humans create when we read and share news over social media, thereby enabling the incredible propagation of fake news that we see permeate the world today. And this isn't just a simple process: once you incorporate humans (and human judgement) into this network, it becomes infinitely more complicated to model and predict.\"), mdx(\"p\", null, \"I definitely feel like this is something that I've been trying to articulate, and so I'm happy to see it laid out in this clear manner (unlike the way my brain organises its information, if it does that at all). It also has the same sort of flavor as my [\", \"[fairness-project]\", \"] work.\"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-BakColeman:2021wt\"\n  }, \"Bak-Coleman, J.B. et al., 2021. Stewardship of global collective behavior. Proc Natl Acad Sci USA, 118(27), p.e2025764118.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-BakColeman:2021wt\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/stewardship-of-global-collective-beahvior/","title":"Stewardship of Global Collective Behaviour","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","draft":false},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"from_paper\", \"statistics\", \"research\", \"classic_papers\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"two-cultures\"\n  }, \"Two Cultures\"), mdx(\"p\", null, \"src: \", \"(Breiman, 2001)\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-Breiman:2001wl\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-Breiman:2001wl\",\n    \"className\": \"footnote-ref\"\n  }, \"Breiman:2001wl\"))), mdx(\"p\", null, \"Written in 2001, I would say that many of the issues raised in this seminal paper have not changed much in the intervening years.\"), mdx(\"h2\", {\n    \"id\": \"chapter-by-chapter\"\n  }, \"Chapter by Chapter\"), mdx(\"h3\", {\n    \"id\": \"introduction\"\n  }, \"Introduction\"), mdx(\"p\", null, \"We start with data \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \"(\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"x\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"separator\": \"true\"\n  }, \",\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"y\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \")\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"(x,y)\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"x\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mpunct\"\n  }, \",\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"y\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose\"\n  }, \")\"))))), \", and assume there is a black box that relates inputs to outputs, \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"y\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"f\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \"(\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"x\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \")\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"y = f(x)\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.625em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03588em\"\n    }\n  }, \"y\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.10764em\"\n    }\n  }, \"f\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"x\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose\"\n  }, \")\"))))), \". He then differentiates between two cultures: data modelling, and algorithmic modelling.\"), mdx(\"p\", null, \"Data modelling defines a strict stochastic model form of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"f\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"f\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8888799999999999em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.10764em\"\n    }\n  }, \"f\"))))), \", equipped with noise, parameters (i.e. classical statistics). We learn parameters from the data, and do robustness checks.\"), mdx(\"p\", null, \"Algorithmic modelling, on the other hand, makes no assumptions on the form of \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"f\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"f\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8888799999999999em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.10764em\"\n    }\n  }, \"f\"))))), \" -- it simply learns some \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mover\", {\n    parentName: \"mrow\",\n    \"accent\": \"true\"\n  }, mdx(\"mi\", {\n    parentName: \"mover\"\n  }, \"f\"), mdx(\"mo\", {\n    parentName: \"mover\"\n  }, \"^\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\hat{f}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1.1523199999999998em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord accent\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.9578799999999998em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.10764em\"\n    }\n  }, \"f\"))), mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.26344em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"accent-body\",\n    \"style\": {\n      \"left\": \"-0.08332999999999999em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"^\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.19444em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  }))))))))), \" that is close in prediction space to \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"f\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"f\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8888799999999999em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.10764em\"\n    }\n  }, \"f\"))))), \". There are parameters, and structure, but they are on \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mover\", {\n    parentName: \"mrow\",\n    \"accent\": \"true\"\n  }, mdx(\"mi\", {\n    parentName: \"mover\"\n  }, \"f\"), mdx(\"mo\", {\n    parentName: \"mover\"\n  }, \"^\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\hat{f}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1.1523199999999998em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord accent\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.9578799999999998em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.10764em\"\n    }\n  }, \"f\"))), mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.26344em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"accent-body\",\n    \"style\": {\n      \"left\": \"-0.08332999999999999em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"^\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.19444em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  }))))))))), \". Thus, the black box of nature is left intact and untouched.\"), mdx(\"h3\", {\n    \"id\": \"use-of-data-models\"\n  }, \"Use of Data Models\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"This enterprise has at its heart the belief that a statistician, by imagination and by looking at the data, can invent a reasonably good parametric class of models for a complex mechanism devised by nature\")), mdx(\"p\", null, \"He worries that there is an over-reliance on data models, and that people forget that \\\"if the model is a poor emulation of nature, the conclusions may be wrong\\\".\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\"))), mdx(\"p\", null, \"We begin with linear models, the bread-and-butter of a statistician's arsenal. We can probably all recite the model assumptions of this model, which with probability 1 do not hold in practice. That never stopped anyone from claiming significance and writing a paper. More sophisticated practitioners would look at \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"goodness-of-fit\"), \" tests, or even \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"robustness\"), \" checks.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"In a discussion after a presentation of residual analysis in a seminar at Berkeley in 1993, William Cleveland, one of the fathers of residual analysis, admitted that it could not uncover lack of fit in more than four to five dimensions.\")), mdx(\"p\", null, \"What you essentially have is the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"curse of dimensionality\"), \", which makes it difficult (unless you have exponential sample size) to be able to test for anything in high dimensions.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-2\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-2\",\n    \"className\": \"footnote-ref\"\n  }, \"2\")), \" Thus, all the classical things we teach in robust statistics just really aren't that applicable once you deal with non-trivial data sizes.\"), mdx(\"p\", null, \"Then there is the separate issue of guided regression (or, the garden of forking paths, as poetically put by Gelman), which, in the past decade, has come under scrutiny as a result of the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"replication crisis\"), \". He attributes the laissez-faire attitude that statisticians had to this, back in the day, to the preoccupation with the data model.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-3\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-3\",\n    \"className\": \"footnote-ref\"\n  }, \"3\"))), mdx(\"h2\", {\n    \"id\": \"two-decades-on\"\n  }, \"Two Decades On\"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-Breiman:2001wl\"\n  }, \"Breiman, L., 2001. Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author). Statistical Science, 16(3), pp.199\\u2013231. Available at: https://doi.org/10.1214/ss/1009213726.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-Breiman:2001wl\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"In my years of consulting experience, I can definitely attest to the over-reliance on data models, but I think this specific point is more a pedagogical issue than a research-focus one.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-2\"\n  }, \"Intuitively, you don't get linear increase with dimension, but exponential, since it's more about linear combinations of variables.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-2\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-3\"\n  }, \"I think this is a little bit of a stretch. I think the takeaway here is that statisticians need to be very careful about the models they create, since goodness-of-fit tests (and the like) make it very easy to hoodwink oneself into thinking that a procedure is valid, when in fact subtle issues of selection bias may be creeping in. On the other hand, the test data never lies (well, rarely).\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-3\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/two-cultures/","title":"Two Cultures","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","draft":false},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"research\", \"nlp\", \"from_paper\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"unsupervised-language-translation\"\n  }, \"Unsupervised Language Translation\"), mdx(\"p\", null, \"Two papers:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Word translation without parallel data. \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://openreview.net/forum?id=H196sainb\"\n  }, \"OpenReview\"), \" \", \"(Conneau et al., 2017)\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-Conneau:2017wg\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-Conneau:2017wg\",\n    \"className\": \"footnote-ref\"\n  }, \"Conneau:2017wg\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Unsupervised Neural Machine Translation. \", \"[OpenReview]\", \"(Unsupervised Neural Machine Translation) \", \"(Artetxe et al., 2017)\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-Artetxe:2017ta\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-Artetxe:2017ta\",\n    \"className\": \"footnote-ref\"\n  }, \"Artetxe:2017ta\")))), mdx(\"h2\", {\n    \"id\": \"unsupervised-neural-machine-translation\"\n  }, \"Unsupervised Neural Machine Translation\"), mdx(\"p\", null, \"Typically for machine translation, it would be a supervised problem, whereby you have parallel corpora (e.g. UN transcripts). In many cases, however, you don't have such data. Sometimes you might be able to sidestep this problem if there's a bridge language where there does exist parallel datasets. What if you don't have any such data, and simply monolingual data? This would be the unsupervised problem.\"), mdx(\"figure\", {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"600px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/d43aa846ecd8f8dddd3949a0448e1391/d7542/unsup_lang.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"57.333333333333336%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACCUlEQVQoz3WTa08aQRSG/e2N/QlN2g+mqY1W036woFGMCohYFlYQsMr9qlyq6C677I2ZfRpWqYTUk5zMybznvPPOmTMrAL7v/9fnGDzHvETW1GfiCpZtlruyWLwMzvelBO3+Bm3YxKhdMCzEqacO6BeT6JU0RiOH61hB7soigVxSN9c0sQT97DtaVwdcHu1SPwtzFQ3xWDjhT/aQfGyPiWk8E86Kx7pGo1ajXq1QrVQol8t02i2MsY7j2MxuN8i9p1K7YD3RJaTU2Em3A4LuyOJj5BrNWFCoqJfEE0lO4klUVaWYzxNPnKPm8kgpkMBT6QO92yKnxT7ZcgflujtrBiNtTCRdxTAXCH+mGsTybbZiN3SHWgDsZxpE8x2E5yCljz3R8FwbfIkvBb4vmU4FQgjwBXLW6DnhfqbCYabAdlTlptnEcXTC5znOf7cCAtu2cT2J502xTIPebZdWs4Fp6NgTE2tiLhD6kK2eElLW2UtvsqtsEE5tEEp9odS9DJJsR9C7+sTd9RG92BYPiU0akc90jr8ySnxjcPYDy9BfH8VxXWzH/ufOy+p6XqBwdvYwt0qt8oud0xJRpchxpgRTi7vegO8necbm0ti8bT7Ch1FhlXo9w3ayzaFaJazUA7T3MGYtUnx95bd+yes8+ggJ434KczzgXpvwpBs86iZSTLEdl8GDhut6AeFfLzQ1/bqCMxoAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Architecture of the proposed system.\",\n    \"title\": \"Architecture of the proposed system.\",\n    \"src\": \"/static/d43aa846ecd8f8dddd3949a0448e1391/0a47e/unsup_lang.png\",\n    \"srcSet\": [\"/static/d43aa846ecd8f8dddd3949a0448e1391/8a4e8/unsup_lang.png 150w\", \"/static/d43aa846ecd8f8dddd3949a0448e1391/5a46d/unsup_lang.png 300w\", \"/static/d43aa846ecd8f8dddd3949a0448e1391/0a47e/unsup_lang.png 600w\", \"/static/d43aa846ecd8f8dddd3949a0448e1391/d7542/unsup_lang.png 810w\"],\n    \"sizes\": \"(max-width: 600px) 100vw, 600px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Architecture of the proposed system.\"), \"\\n  \"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"They assume the existence of an \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"unsupervised cross-lingual embedding\"), \". This is a key assumption, and their entire architecture sort of rests on this. Essentially, you form embedding vectors for two languages separately (which is unsupervised), and then \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"align\"), \" them algorithmically, so that they now reside in a shared, bilingual space.\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"From there, you can use a \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"shared encoder\"), \", since the two inputs are from a shared space. Recall that the goal of the encoder is to reduce/sparsify the input (from which the decoder can reproduce it) -- in the case of a shared encoder, by virtue of the cross-lingual embedding, you're getting a language-agnostic encoder, which hopefully gets at the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"meaning\"), \" of the words.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Again, somewhat naturally, this means you're basically building both directions of the translation, or what they call the \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"dual structure\"), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Altogether, what you get is a pretty cute autoencoder architecture. Essentially, what you're doing is training something like a [\", \"[siamese-networks]\", \"]; you have the shared encoder, and then two separate decoders for each language. During training, you're basically doing normal autoencoding, and then during inference, you just \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"flip\"), \" -- cute!\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"To ensure this isn't a trivial task, they take the framework on the denoising autoencoder, and shuffle the words around in the input.\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-2\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-2\",\n    \"className\": \"footnote-ref\"\n  }, \"2\")), \" I guess it's a little difficult to do something like squeeze all these tokens into a smaller dimension. However, this clearly doesn't do that much -- it's just scrambling.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"The trick is then to adapt the so-called back-translation approach of \", \"(Sennrich et al., 2016)\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-sennrich-etal-2016-improving\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-sennrich-etal-2016-improving\",\n    \"className\": \"footnote-ref\"\n  }, \"sennrich-etal-2016-improving\")), \" in a sort of alternating fashion. I think what it boils down to is just flipping the switch during training.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Altogether, you have two types of mini-batch training schemes, and you alternate between the two. The first is same language (L1 + \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"\\u03F5\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\epsilon\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.43056em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"\\u03F5\"))))), \" -> L1), adding noise. The second is different language (L1 -> L2), using the current state of the NMT (neural machine translation) model as the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"data\"), \".\")), mdx(\"h2\", {\n    \"id\": \"word-translation-without-parallel-data\"\n  }, \"Word Translation Without Parallel Data\"), mdx(\"figure\", {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"600px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/fe42ead7377e747d026d00efa3d9f569/e0885/unsup_lang_2.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"24%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA+UlEQVQY01WQ2W6DMAAE+f/vq1pFSRvSOGAuAzY+sA1TBalVOtI+7bzsFnnbeLLvO7+klI68EmP85+Scj7zy7IuhaXBSsirFtu84lxDiwTTPh+RGjRk0dyGOPq8rdlyQUlI/JCkmYoh4ux5+kReD7gZaqfE+cb93SKmYBoseHabX3C7f9K3CTJ5lWpirnkdZo+RIe2+ZO00nFClmCtf3BKWoxEjbLSjl+LoKqnPJ9e3CIBX1teL0cWIoJUr0GKn4fL9wO9+oywYlZ8ZmJq2JwhtDMJotZ0JIWBux1rFtmdV77GzxS8B5x5YS3njsZPHOP18j2MAyub/JP52SgDqKuDFJAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Toy illustration.\",\n    \"title\": \"Toy illustration.\",\n    \"src\": \"/static/fe42ead7377e747d026d00efa3d9f569/0a47e/unsup_lang_2.png\",\n    \"srcSet\": [\"/static/fe42ead7377e747d026d00efa3d9f569/8a4e8/unsup_lang_2.png 150w\", \"/static/fe42ead7377e747d026d00efa3d9f569/5a46d/unsup_lang_2.png 300w\", \"/static/fe42ead7377e747d026d00efa3d9f569/0a47e/unsup_lang_2.png 600w\", \"/static/fe42ead7377e747d026d00efa3d9f569/1cfc2/unsup_lang_2.png 900w\", \"/static/fe42ead7377e747d026d00efa3d9f569/e0885/unsup_lang_2.png 918w\"],\n    \"sizes\": \"(max-width: 600px) 100vw, 600px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Toy illustration.\"), \"\\n  \"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"With the similar constraint of just having two monolingual corpora, they tackle step zero of the first paper, namely how to align two embeddings (the unsupervised cross-lingual embedding step). They employ \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"adversarial training\"), \" (like GANs).\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-3\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-3\",\n    \"className\": \"footnote-ref\"\n  }, \"3\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"A little history of these cross-lingual embeddings: \", \"(Mikolov et al., 2013)\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-Mikolov:2013tp\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-Mikolov:2013tp\",\n    \"className\": \"footnote-ref\"\n  }, \"Mikolov:2013tp\")), \" noticed structural similarities in embeddings across languages, and so used a parallel vocabulary (of 5000 words) to do alignment. Later versions used even smaller intersection sets (e.g. parallel vocabulary of aligned digits of \", \"(Artetxe et al., 2017)\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-artetxe-etal-2017-learning\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-artetxe-etal-2017-learning\",\n    \"className\": \"footnote-ref\"\n  }, \"artetxe-etal-2017-learning\")), \"). The optimisation problem is to learn a linear mapping \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"W\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"W\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68333em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"W\"))))), \" such that\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-4\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-4\",\n    \"className\": \"footnote-ref\"\n  }, \"4\")), \" \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"W\"), mdx(\"mo\", {\n    parentName: \"msup\"\n  }, \"\\u22C6\")), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"arg\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2061\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mo\", {\n    parentName: \"msub\"\n  }, mdx(\"mi\", {\n    parentName: \"mo\"\n  }, \"min\"), mdx(\"mo\", {\n    parentName: \"mo\"\n  }, \"\\u2061\")), mdx(\"mrow\", {\n    parentName: \"msub\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"W\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2208\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"M\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"d\")), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \"(\"), mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"double-struck\"\n  }, \"R\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"stretchy\": \"false\"\n  }, \")\"))), mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"normal\"\n  }, \"\\u2225\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"W\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"X\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2212\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"Y\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\",\n    \"mathvariant\": \"normal\"\n  }, \"\\u2225\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"F\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"W^\\\\star = \\\\arg\\\\min_{W \\\\in M_d (\\\\mathbb{R})} \\\\| W X - Y \\\\|_{F}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.688696em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"W\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.688696em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mbin mtight\"\n  }, \"\\u22C6\")))))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1.1052em\",\n      \"verticalAlign\": \"-0.3551999999999999em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mop\"\n  }, \"ar\", mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"marginRight\": \"0.01389em\"\n    }\n  }, \"g\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mop\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mop\"\n  }, \"min\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.34480000000000005em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5198em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"W\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel mtight\"\n  }, \"\\u2208\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\",\n    \"style\": {\n      \"marginRight\": \"0.10903em\"\n    }\n  }, \"M\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.3448em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.3487714285714287em\",\n      \"marginLeft\": \"-0.10903em\",\n      \"marginRight\": \"0.07142857142857144em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.5em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size3 size1 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"d\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15122857142857138em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen mtight\"\n  }, \"(\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathbb mtight\"\n  }, \"R\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose mtight\"\n  }, \")\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.3551999999999999em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"\\u2225\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"W\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.07847em\"\n    }\n  }, \"X\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2222222222222222em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mbin\"\n  }, \"\\u2212\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2222222222222222em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1em\",\n      \"verticalAlign\": \"-0.25em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.22222em\"\n    }\n  }, \"Y\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"\\u2225\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.32833099999999993em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"0em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"F\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))))))), \".\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Given two sets of word embeddings \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"script\"\n  }, \"X\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"separator\": \"true\"\n  }, \",\"), mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"script\"\n  }, \"Y\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\mathcal{X}, \\\\mathcal{Y}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8777699999999999em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathcal\",\n    \"style\": {\n      \"marginRight\": \"0.14643em\"\n    }\n  }, \"X\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mpunct\"\n  }, \",\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathcal\",\n    \"style\": {\n      \"marginRight\": \"0.08222em\"\n    }\n  }, \"Y\")))))), \", the discriminator tries to distinguish between elements randomly sampled from \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"W\"), mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"script\"\n  }, \"X\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"W\\\\mathcal{X}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68333em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"W\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathcal\",\n    \"style\": {\n      \"marginRight\": \"0.14643em\"\n    }\n  }, \"X\")))))), \" and \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"script\"\n  }, \"Y\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\mathcal{Y}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.78055em\",\n      \"verticalAlign\": \"-0.09722em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathcal\",\n    \"style\": {\n      \"marginRight\": \"0.08222em\"\n    }\n  }, \"Y\")))))), \", while the linear mapping \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"W\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"W\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68333em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"W\"))))), \" (generator) is \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"learned\"), \" to make that task difficult.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Refinement step: the above procedure doesn't do that well, because it doesn't take into account word frequency.\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-5\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-5\",\n    \"className\": \"footnote-ref\"\n  }, \"5\")), \" But now you have something like a supervised dictionary (set of common words): you pick the most frequent words and their mutual nearest neighbours, set this as your \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"synthetic dictionary\"), \", and apply the Procrustes algorithm to align once again.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"It's pretty important to ensure that the dictionary is correct, since you're basically using that as the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"ground truth\"), \" by which you align. Using \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"k\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"k\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.69444em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03148em\"\n    }\n  }, \"k\"))))), \"-NN is problematic for many reasons (in high dimensions), but one is that it's asymmetric, and you get hubs (NN of many vectors). They therefore devise a new (similarity) measure, derived from \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"k\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"k\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.69444em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03148em\"\n    }\n  }, \"k\"))))), \"-NN: essentially for a word, you consider the \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"k\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"k\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.69444em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03148em\"\n    }\n  }, \"k\"))))), \"-NNs in the other domain, and then you take the average cosine similarity. You then penalise the cosine similarity of a pair of vectors by this sort-of neighbourhood concentration.\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-6\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-6\",\n    \"className\": \"footnote-ref\"\n  }, \"6\")))), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-Conneau:2017wg\"\n  }, \"Conneau, A. et al., 2017. Word Translation Without Parallel Data. arXiv.org.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-Conneau:2017wg\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-Artetxe:2017ta\"\n  }, \"Artetxe, M., Labaka, G., Agirre, E., et al., 2017. Unsupervised Neural Machine Translation. arXiv.org.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-Artetxe:2017ta\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"It's only a small stretch to imagine performing this on multiple languages, so that you get some notion of a universal language space.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-2\"\n  }, \"I'm so used to bag-of-word style models, or even the more classical word embeddings that didn't care about the ordering in the window, that this just feels like that -- we're harking back to the wild-wild-west, when we didn't have context-aware embeddings.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-2\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-sennrich-etal-2016-improving\"\n  }, \"Sennrich, R., Haddow, B. & Birch, A., 2016. Improving Neural Machine Translation Models with Monolingual Data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Berlin, Germany: Association for Computational Linguistics, pp. 86\\u201396.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-sennrich-etal-2016-improving\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-3\"\n  }, \"And in fact follow the same training mechanism as GANs.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-3\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-Mikolov:2013tp\"\n  }, \"Mikolov, T., Le, Q.V. & Sutskever, I., 2013. Exploiting Similarities among Languages for Machine Translation. arXiv.org.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-Mikolov:2013tp\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-artetxe-etal-2017-learning\"\n  }, \"Artetxe, M., Labaka, G. & Agirre, E., 2017. Learning bilingual word embeddings with (almost) no bilingual data. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vancouver, Canada: Association for Computational Linguistics, pp. 451\\u2013462.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-artetxe-etal-2017-learning\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-4\"\n  }, \"It turns out that enforcing \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"W\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"W\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68333em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"W\"))))), \" to be orthogonal (i.e. a rotation) gives better results, which reduces to the Procrustes algorithm, much like what we used for the dynamic word embedding project.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-4\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-5\"\n  }, \"Why don't they change the procedure to weigh points according to their frequency then?\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-5\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-6\"\n  }, \"Intuitively, you penalise vectors whose NN set is concentrated (i.e. it's difficult to tell who is the actual nearest neighbour).\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-6\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/unsupervised-language-translation/","title":"Unsupervised Language Translation","lastUpdated":"4/16/2022","lastUpdatedAt":"2022-04-16T07:10:21.000Z","gitCreatedAt":"2022-04-15T20:31:09.000Z"}}]}},"pageContext":{"slug":"/tags/research/","tag":"research","sidebarItems":[{"title":"","items":[{"title":"Recently Updated","url":"/latest/","collapse":true,"indent":false,"items":[{"title":"10-24: To E2E or Not","url":"/to-e2e-or-not/"},{"title":"10-19: Generalisation-Walkthrough","url":"/generalisation-walkthrough/"},{"title":"10-12: Poker AI","url":"/poker-ai/"},{"title":"10-10: Generalisation-Theory","url":"/generalisation-theory/"},{"title":"10-05: Generalisation Paper","url":"/generalisation-paper/"},{"title":"09-24: Generative Models","url":"/generative-models/"},{"title":"09-23: Score-Based-Models","url":"/score-based-models/"},{"title":"09-23: Diffusion-Models","url":"/diffusion-models/"},{"title":"07-29: Test Augmentation","url":"/test-augmentation/"},{"title":"07-28: Multi-Modal Learning","url":"/multi-modal-learning/"}]}]},{"title":"Tags","items":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}]}],"tagsGroups":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}