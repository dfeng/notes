{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/generalised-neural-networks/",
    "result": {"data":{"mdx":{"id":"8d2b5d90-de2e-5fa4-b56f-bcbe06aa4b10","tableOfContents":{"items":[{"url":"#generalized-neural-networks","title":"Generalized Neural Networks","items":[{"url":"#the-bad","title":"The Bad"},{"url":"#the-good","title":"The Good?"},{"url":"#literature","title":"Literature"}]}]},"fields":{"title":"Generalized Neural Networks","slug":"/generalised-neural-networks/","url":"https://deepmind.vercel.app/generalised-neural-networks/","editUrl":"https://github.com/dfeng/notes/tree/main/generalised-neural-networks.md","lastUpdatedAt":"2022-01-29T13:24:59.000Z","lastUpdated":"1/29/2022","gitCreatedAt":"2022-01-22T10:54:29.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":["neural_networks","machine_learning"],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"neural_networks\", \"machine_learning\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"generalized-neural-networks\"\n  }, \"Generalized Neural Networks\"), mdx(\"p\", null, \"Recently, there has been a flurry of work that seeks to build architectures that are domain-agnostic. Perhaps unsurprisingly, most of the work in this direction uses \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/transformers/\",\n    \"title\": \"Transformers\"\n  }, \"transformers\"), \" at its core, given its (apparent) flexibility. The thesis is that domain-specific architectures work great in their particular niche, but the moment something changes, even slightly, then you're back to square one in terms of training, and square three in terms of architecture.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\")), \" Wouldn't it be great, then, to have some generic architecture that just works across all these domains?\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-2\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-2\",\n    \"className\": \"footnote-ref\"\n  }, \"2\"))), mdx(\"p\", null, \"At first blush, this seems like a no-brainer: you no longer have to build specialized architectures depending on the problem at hand, and there doesn't seem to be much downside. However, I think it's actually worthwhile to spend some time questioning this assumption.\"), mdx(\"h2\", {\n    \"id\": \"the-bad\"\n  }, \"The Bad\"), mdx(\"h3\", {\n    \"id\": \"visual-tasks\"\n  }, \"Visual Tasks\"), mdx(\"p\", null, \"Let's consider the domain of visual tasks, and in particular, the use of convolutions. While convolutions are clearly a form of inductive bias, I don't see any problem with using them as just one of several fundamental building blocks (something that cares mostly about local 2D statistics). I think stereo-pairs is a good working example here: with the current architectures, it is indeed the case that moving from single to stereo is a non-trivial architectural task that requires a choice (about how to fuse the two inputs).\"), mdx(\"p\", null, \"I also can't help but compare to how our visual system works, noting that despite our ability to handle generic visual tasks, part of the system utilizes convolutions. Granted, the fruits of evolution are not a justification in itself, but at the very least it's an existence proof that we needn't throw the baby out with the bath water on our pursuit of generalisability. And if we're going with biologically inspiration, I think stereo inputs should just be the de-facto, as that gives us the depth perception that we need to better understand the world. In terms of inputs, why not just subscribe to the inputs that we as humans have: stereo visual inputs, stereo audial inputs, and some complex input that is our nervous system.\"), mdx(\"p\", null, \"Having said all this, I realise the problem is that I'm coming at this from the perspective of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/artificial-generalised-intelligence/\",\n    \"title\": \"Artificial Generalised Intelligence\"\n  }, \"artificial-generalised-intelligence\"), \" (hence taking inspiration from how we do things). The space of inputs that machine learning covers is much wider than what we (as humans) get as inputs. That doesn't negate my argument that it makes more sense to work with a few fundamental units (instead of just one), but at least I can see why it might not be as straightforward as just following evolution.\"), mdx(\"h3\", {\n    \"id\": \"efficiency\"\n  }, \"Efficiency\"), mdx(\"p\", null, \"Convolutions are a biologically inspired, incredibly efficient means of processing image data. My guess is that the upper bound on what these kinds of generalised neural networks can achieve is to essentially reinvent the wheel and reproduce convolutions. And perhaps future models are flexible enough to do that. For now, though, the best we can hope for is to achieve some sort of parity in performance, though at the (terrible) expense of efficiency and compute. Granted, I do think visual tasks are an easy target, since there already is a simple, obvious architecture which gets you very far. I'm less familiar with the audio world.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-3\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-3\",\n    \"className\": \"footnote-ref\"\n  }, \"3\"))), mdx(\"h3\", {\n    \"id\": \"great-power-great-responsibility\"\n  }, \"Great Power, Great Responsibility\"), mdx(\"p\", null, \"Letting the data speak for itself comes with its own problems (and we're not even talking about the [\", \"[fairness-project]\", \"]). At a high level, this is similar to the problem of [\", \"[reinforcement-learning]\", \"] (paperclip): given a sufficiently powerful generic algorithm, it will find ways to achieve the goal assigned to it that are possibly counter to what we would like it to learn. That is, it will pick up on correlations and use those, operating under the assumption that correlation implies causation ([\", \"[causal-inference]\", \"]). A simple example is, when classifying a boat, a generic algorithm will use the whole image (e.g. presence of the sea) to help it to classify, maybe to the point where it doesn't even care about the specifics of the target object (see also \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/computer-vision-tasks/\",\n    \"title\": \"Computer Vision Tasks\"\n  }, \"computer-vision-tasks\"), \").\"), mdx(\"p\", null, \"In some sense, with these kinds of generalised architectures, the inductive bias step is now hidden in the regularisation techniques. Now, it's probable that regularisation is actually where you want to inject these kinds of biases (as opposed to in the architecture). Again with relating it to humans, our generalised intelligence doesn't have the same kinds of problem, a simple reason being that our learnings are not the result of some simple loss function. That is, it's the fact that we're doing a \\\"simple\\\" non-convex optimization that leads to these kinds of quirky solutions.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-4\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-4\",\n    \"className\": \"footnote-ref\"\n  }, \"4\"))), mdx(\"h2\", {\n    \"id\": \"the-good\"\n  }, \"The Good?\"), mdx(\"p\", null, \"When such generic architectures actually succeed, it provides fairly strong evidence that this particular architecture is a powerful fundamental building block, and perhaps should be used in the later layers of a generalised neural network. On the other hand, it's \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"almost\"), \" akin to saying that \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"NOT\"), \" gates are a powerful building block for computers \\u2013 how much do we learn from such a statement in terms of understanding how computers work?\"), mdx(\"p\", null, \"Being domain-agnostic seems like it would be\\nMeanwhile, being input/output format agnostic lets you experiment with combining different input sources \"), mdx(\"p\", null, \"It also speaks in part to the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/bitter-lesson/\",\n    \"title\": \"Bitter Lesson\"\n  }, \"bitter-lesson\"), \". However, I think the regime here is a little different: there are \"), mdx(\"h2\", {\n    \"id\": \"literature\"\n  }, \"Literature\"), mdx(\"h3\", {\n    \"id\": \"perceiver\"\n  }, \"Perceiver\"), mdx(\"p\", null, \"src: \", \"(Jaegle et al., 2021)\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-jaegle2021perceiver\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-jaegle2021perceiver\",\n    \"className\": \"footnote-ref\"\n  }, \"jaegle2021perceiver\"))), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"A simple example is going from single images to stereo pairs, akin to how our own visual system works.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-2\"\n  }, \"In the words of LeCun, let the data speak for itself.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-2\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-3\"\n  }, \"Though in my brief stint, I remember that convolutions (just 1D) also played a role.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-3\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-4\"\n  }, \"And if you think about it, no amount of injecting common-sense could really sidestep this fundamental flaw.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-4\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-jaegle2021perceiver\"\n  }, \"Jaegle, A. et al., 2021. Perceiver: General Perception with Iterative Attention,\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-jaegle2021perceiver\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\ntags:\n - neural_networks\n - machine_learning\n---\n\n# Generalized Neural Networks\n\nRecently, there has been a flurry of work that seeks to build architectures that are domain-agnostic. Perhaps unsurprisingly, most of the work in this direction uses [[transformers]] at its core, given its (apparent) flexibility. The thesis is that domain-specific architectures work great in their particular niche, but the moment something changes, even slightly, then you're back to square one in terms of training, and square three in terms of architecture.^[A simple example is going from single images to stereo pairs, akin to how our own visual system works.] Wouldn't it be great, then, to have some generic architecture that just works across all these domains?^[In the words of LeCun, let the data speak for itself.]\n\nAt first blush, this seems like a no-brainer: you no longer have to build specialized architectures depending on the problem at hand, and there doesn't seem to be much downside. However, I think it's actually worthwhile to spend some time questioning this assumption.\n\n## The Bad\n\n### Visual Tasks\n\nLet's consider the domain of visual tasks, and in particular, the use of convolutions. While convolutions are clearly a form of inductive bias, I don't see any problem with using them as just one of several fundamental building blocks (something that cares mostly about local 2D statistics). I think stereo-pairs is a good working example here: with the current architectures, it is indeed the case that moving from single to stereo is a non-trivial architectural task that requires a choice (about how to fuse the two inputs).\n\nI also can't help but compare to how our visual system works, noting that despite our ability to handle generic visual tasks, part of the system utilizes convolutions. Granted, the fruits of evolution are not a justification in itself, but at the very least it's an existence proof that we needn't throw the baby out with the bath water on our pursuit of generalisability. And if we're going with biologically inspiration, I think stereo inputs should just be the de-facto, as that gives us the depth perception that we need to better understand the world. In terms of inputs, why not just subscribe to the inputs that we as humans have: stereo visual inputs, stereo audial inputs, and some complex input that is our nervous system.\n\nHaving said all this, I realise the problem is that I'm coming at this from the perspective of [[artificial-generalised-intelligence]] (hence taking inspiration from how we do things). The space of inputs that machine learning covers is much wider than what we (as humans) get as inputs. That doesn't negate my argument that it makes more sense to work with a few fundamental units (instead of just one), but at least I can see why it might not be as straightforward as just following evolution.\n\n### Efficiency\n\nConvolutions are a biologically inspired, incredibly efficient means of processing image data. My guess is that the upper bound on what these kinds of generalised neural networks can achieve is to essentially reinvent the wheel and reproduce convolutions. And perhaps future models are flexible enough to do that. For now, though, the best we can hope for is to achieve some sort of parity in performance, though at the (terrible) expense of efficiency and compute. Granted, I do think visual tasks are an easy target, since there already is a simple, obvious architecture which gets you very far. I'm less familiar with the audio world.^[Though in my brief stint, I remember that convolutions (just 1D) also played a role.]\n\n### Great Power, Great Responsibility\n\nLetting the data speak for itself comes with its own problems (and we're not even talking about the [[fairness-project]]). At a high level, this is similar to the problem of [[reinforcement-learning]] (paperclip): given a sufficiently powerful generic algorithm, it will find ways to achieve the goal assigned to it that are possibly counter to what we would like it to learn. That is, it will pick up on correlations and use those, operating under the assumption that correlation implies causation ([[causal-inference]]). A simple example is, when classifying a boat, a generic algorithm will use the whole image (e.g. presence of the sea) to help it to classify, maybe to the point where it doesn't even care about the specifics of the target object (see also [[computer-vision-tasks]]).\n\nIn some sense, with these kinds of generalised architectures, the inductive bias step is now hidden in the regularisation techniques. Now, it's probable that regularisation is actually where you want to inject these kinds of biases (as opposed to in the architecture). Again with relating it to humans, our generalised intelligence doesn't have the same kinds of problem, a simple reason being that our learnings are not the result of some simple loss function. That is, it's the fact that we're doing a \"simple\" non-convex optimization that leads to these kinds of quirky solutions.^[And if you think about it, no amount of injecting common-sense could really sidestep this fundamental flaw.]\n\n## The Good?\n\nWhen such generic architectures actually succeed, it provides fairly strong evidence that this particular architecture is a powerful fundamental building block, and perhaps should be used in the later layers of a generalised neural network. On the other hand, it's *almost* akin to saying that `NOT` gates are a powerful building block for computers – how much do we learn from such a statement in terms of understanding how computers work?\n\nBeing domain-agnostic seems like it would be \nMeanwhile, being input/output format agnostic lets you experiment with combining different input sources \n\nIt also speaks in part to the [[bitter-lesson]]. However, I think the regime here is a little different: there are \n\n## Literature\n\n### Perceiver\n\nsrc: [@jaegle2021perceiver]\n\n\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\n[transformers]: transformers.md \"Transformers\"\n[artificial-generalised-intelligence]: artificial-generalised-intelligence.md \"Artificial Generalised Intelligence\"\n[computer-vision-tasks]: computer-vision-tasks.md \"Computer Vision Tasks\"\n[bitter-lesson]: bitter-lesson.md \"Bitter Lesson\"\n[//end]: # \"Autogenerated link references\"","excerpt":"Generalized Neural Networks Recently, there has been a flurry of work that seeks to build architectures that are domain-agnostic. Perhaps u…","outboundReferences":[{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"artificial_intelligence\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"artificial-generalised-intelligence\"\n  }, \"Artificial Generalised Intelligence\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/artificial-generalised-intelligence/","title":"Artificial Generalised Intelligence","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"from_article\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"bitter-lesson\"\n  }, \"Bitter Lesson\"), mdx(\"p\", null, \"src: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://incompleteideas.net/IncIdeas/BitterLesson.html\"\n  }, \"blog\")), mdx(\"h2\", {\n    \"id\": \"summary\"\n  }, \"Summary\"), mdx(\"p\", null, \"In AI research, leveraging computation > incorporating domain knowledge. Given finite resources, it always pays to improve computation than to incorporate domain knowledge.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"the only thing that matters in the long run is the leveraging of computation\")), mdx(\"p\", null, \"This \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitter\"), \" lesson arises in part because of our anthropocentric view (that's not how we as humans solve \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"insert_difficult_task\"), \"!), biasing us towards more elaborate systems.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation.\")), mdx(\"p\", null, \"Also, there's a trade-off, especially as the injection of human knowledge gets more elaborate, then there's usually a computation cost.\"), mdx(\"h3\", {\n    \"id\": \"history\"\n  }, \"History\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Chess: search-based approaches beat out leveraging human understanding of structure of chess\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Go: key insight was \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"learning by self-play\"), \", which enabled massive computation to be brought to bear\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Speech Recognition: linguistics, we have the Unreasonable Effectiveness paper of Norvig\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"More recently, the massive scale language models (like GPT-3) show that larger models/datasets outperform fancier architectures (and history repeats itself)\")))), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.\")), mdx(\"p\", null, \"Even though a lot of our knowledge is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"guided\"), \", for most of our general-purpose intelligence, it just happens naturally, so it should be similarly for building AI.\"), mdx(\"h2\", {\n    \"id\": \"thoughts\"\n  }, \"Thoughts\"), mdx(\"p\", null, \"I'm not as familiar with the AI game literature, but at least in the context of NLP/image classification and DL, there seems to be an ideal sweet-spot in terms of finding the right kind of architecture that's powerful enough to learn, but is simple enough that you can run it on an extreme scale. I think that's partly why we still continue to innovate on the model side. If we hadn't done so, then we wouldn't have gotten \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/transformers/\",\n    \"title\": \"Transformers\"\n  }, \"transformers\"), \", which has been a boon for NLP.\"), mdx(\"p\", null, \"What is pretty clear is that domain-knowledge injection is not \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"scalable\"), \" (think expert systems back in the day). What's better are general-purpose methodologies, and the more general-purpose, the better (update: no longer think this relationship is linear: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/generalised-neural-networks/\",\n    \"title\": \"Generalized Neural Networks\"\n  }, \"generalised-neural-networks\"), \"). However, this would suggest that something like CNNs are actually \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"suboptimal\"), \", since convolutions are definitely highly specific to image classification. But I think that's part of the allure of [\", \"[graph-neural-networks]\", \"].\"), mdx(\"p\", null, \"Given the successes of CNN in image recognition, I suspect that for specific domain tasks, a little bit of domain knowledge can go a very long way (it's not like it's hard-coding edge detection, so it's still pretty general purpose).\"), mdx(\"p\", null, \"Finally, it feels like we just need to be better at \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"learning-to-learn\"), \" (\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/meta-learning/\",\n    \"title\": \"Meta Learning\"\n  }, \"meta-learning\"), \"). I don't think it's necessarily a bad thing to take inspiration from human intelligence (since we're the only successful example). So, ultimately, I think the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitter lesson\"), \" is really just a stop-gap until we can sufficiently narrow the emulation gap.\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/bitter-lesson/","title":"Bitter Lesson","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"computer_vision\", \"biologically_inspired\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"computer-vision-tasks\"\n  }, \"Computer Vision Tasks\"), mdx(\"p\", null, \"Question: what are the key components of a computer vision task?\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\"))), mdx(\"p\", null, \"This question is inextricably linked to how our vision system works (evolved).\"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"From thinking about convolutional layers and what makes them \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"specialized\"), \".\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/computer-vision-tasks/","title":"Computer Vision Tasks","shouldShowTitle":false}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"machine_learning\", \"neural_networks\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"transformers\"\n  }, \"Transformers\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"references:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html\"\n  }, \"lil-log\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://distill.pub/2016/augmented-rnns/\"\n  }, \"distill\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://d2l.ai/chapter_attention-mechanisms/transformer.html\"\n  }, \"ebook-chapter\"), \" on transformers (actually this ebook isn't great, as it ends up being more about the implementation)\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"it turns out that #attention is an earlier concept, which itself is motivated by the encoder-decoder sequence-to-sequence architecture\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"img\", {\n    parentName: \"li\",\n    \"src\": \"https://karpathy.github.io/assets/rnn/diags.jpeg\",\n    \"alt\": null\n  })), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"(oops) I didn't really understand this diagram:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"sequence to sequence models are essentially the third diagram, where basically the input sequence and output sequence are asynchronous\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"versus the normal rnn, which takes the output as the input\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"I really like the example of 1-to-many, image-to-caption, so your input is not a sequence, but your output is\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"seq2seq example is the translation program, where importantly the input and output sequence don't have to be the same length (due to the way languages differ in their realisations of the same meaning)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"the encoder is the rnn on the input sequence, and this culminates into the last hidden layer\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"this is essentially the \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"context\"), \" vector: the idea here is that this (fixed-length) vector captures all the information about the sentence\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"key: this acts like a sort of \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"informational bottleneck\"), \", and actually is the impetus for the attention mechanic\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"key point (via this \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1703.01619.pdf\"\n  }, \"tutorial\"), \"):\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"instead of having everything represented as the last hidden layer (fixed-length), why not just look at all the hidden layers (vectors representing each word)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"but, that would be \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"variable\"), \" length, so instead just look at a linear combination of those hidden layers. this linear combination is learned, and is basically \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"attention\")))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Transformers #todo\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"\\\"prior art\\\"\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"CNN: easy to parallelise, but aren't recurrent (can't capture sequential dependency)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RNN: reverse\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"goal of transformers/attention is achieve \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"parallelization\"), \" and \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"recurrence\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"by appealing to \\\"attention\\\" to get the recurrence (?)\")))))), mdx(\"h2\", {\n    \"id\": \"transformers-1\"\n  }, \"Transformers\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"key is \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"multi-head self-attention\"), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"encoded representation of input: key-value pairs (\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"K\"), mdx(\"mo\", {\n    parentName: \"mrow\",\n    \"separator\": \"true\"\n  }, \",\"), mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"V\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2208\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\",\n    \"mathvariant\": \"double-struck\"\n  }, \"R\"), mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"n\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"K,V \\\\in \\\\mathbb{R}^{n}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8777699999999999em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.07153em\"\n    }\n  }, \"K\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mpunct\"\n  }, \",\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.16666666666666666em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.22222em\"\n    }\n  }, \"V\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"\\u2208\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68889em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathbb\"\n  }, \"R\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.664392em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"n\"))))))))))))), \")\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"corresponding to hidden states\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"previous output is compressed into query \", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"Q\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"\\u2208\"), mdx(\"msup\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msup\",\n    \"mathvariant\": \"double-struck\"\n  }, \"R\"), mdx(\"mi\", {\n    parentName: \"msup\"\n  }, \"m\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"Q \\\\in \\\\mathbb{R}^{m}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.8777699999999999em\",\n      \"verticalAlign\": \"-0.19444em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"Q\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"\\u2208\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68889em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathbb\"\n  }, \"R\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.664392em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.063em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"m\"))))))))))))), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"output of the transformer is a weighted sum of the values (\", mdx(\"span\", {\n    parentName: \"li\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"V\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"V\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.68333em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.22222em\"\n    }\n  }, \"V\"))))), \").\")))), mdx(\"h2\", {\n    \"id\": \"todo\"\n  }, \"Todo\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Visualising and Measuring the Geometry of BERT \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1906.02715.pdf\"\n  }, \"arXiv\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"http://www.peterbloem.nl/blog/transformers\"\n  }, \"random blog\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"pretty intuitive description of transformers on \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://nostalgebraist.tumblr.com/post/185326092369/the-transformer-explained\"\n  }, \"tumblr\"), \", via the LessWrong community\")));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/transformers/","title":"Transformers","shouldShowTitle":false}}],"inboundReferences":[{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"from_article\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"bitter-lesson\"\n  }, \"Bitter Lesson\"), mdx(\"p\", null, \"src: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://incompleteideas.net/IncIdeas/BitterLesson.html\"\n  }, \"blog\")), mdx(\"h2\", {\n    \"id\": \"summary\"\n  }, \"Summary\"), mdx(\"p\", null, \"In AI research, leveraging computation > incorporating domain knowledge. Given finite resources, it always pays to improve computation than to incorporate domain knowledge.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"the only thing that matters in the long run is the leveraging of computation\")), mdx(\"p\", null, \"This \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitter\"), \" lesson arises in part because of our anthropocentric view (that's not how we as humans solve \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"insert_difficult_task\"), \"!), biasing us towards more elaborate systems.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation.\")), mdx(\"p\", null, \"Also, there's a trade-off, especially as the injection of human knowledge gets more elaborate, then there's usually a computation cost.\"), mdx(\"h3\", {\n    \"id\": \"history\"\n  }, \"History\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Chess: search-based approaches beat out leveraging human understanding of structure of chess\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Go: key insight was \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"learning by self-play\"), \", which enabled massive computation to be brought to bear\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Speech Recognition: linguistics, we have the Unreasonable Effectiveness paper of Norvig\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"More recently, the massive scale language models (like GPT-3) show that larger models/datasets outperform fancier architectures (and history repeats itself)\")))), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.\")), mdx(\"p\", null, \"Even though a lot of our knowledge is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"guided\"), \", for most of our general-purpose intelligence, it just happens naturally, so it should be similarly for building AI.\"), mdx(\"h2\", {\n    \"id\": \"thoughts\"\n  }, \"Thoughts\"), mdx(\"p\", null, \"I'm not as familiar with the AI game literature, but at least in the context of NLP/image classification and DL, there seems to be an ideal sweet-spot in terms of finding the right kind of architecture that's powerful enough to learn, but is simple enough that you can run it on an extreme scale. I think that's partly why we still continue to innovate on the model side. If we hadn't done so, then we wouldn't have gotten \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/transformers/\",\n    \"title\": \"Transformers\"\n  }, \"transformers\"), \", which has been a boon for NLP.\"), mdx(\"p\", null, \"What is pretty clear is that domain-knowledge injection is not \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"scalable\"), \" (think expert systems back in the day). What's better are general-purpose methodologies, and the more general-purpose, the better (update: no longer think this relationship is linear: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/generalised-neural-networks/\",\n    \"title\": \"Generalized Neural Networks\"\n  }, \"generalised-neural-networks\"), \"). However, this would suggest that something like CNNs are actually \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"suboptimal\"), \", since convolutions are definitely highly specific to image classification. But I think that's part of the allure of [\", \"[graph-neural-networks]\", \"].\"), mdx(\"p\", null, \"Given the successes of CNN in image recognition, I suspect that for specific domain tasks, a little bit of domain knowledge can go a very long way (it's not like it's hard-coding edge detection, so it's still pretty general purpose).\"), mdx(\"p\", null, \"Finally, it feels like we just need to be better at \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"learning-to-learn\"), \" (\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/meta-learning/\",\n    \"title\": \"Meta Learning\"\n  }, \"meta-learning\"), \"). I don't think it's necessarily a bad thing to take inspiration from human intelligence (since we're the only successful example). So, ultimately, I think the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"bitter lesson\"), \" is really just a stop-gap until we can sufficiently narrow the emulation gap.\"));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/bitter-lesson/","title":"Bitter Lesson"}},{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"multi-modal-learning\"\n  }, \"Multi-Modal Learning\"), mdx(\"p\", null, \"It seems like we spend a lot of time working in these different seemingly disparate learning domains: supervised, self-supervised, multi-modal supervised \", \"(Desai & Johnson, 2021)\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-desai2021virtex\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-desai2021virtex\",\n    \"className\": \"footnote-ref\"\n  }, \"desai2021virtex\")), \". However, it feels to me like the goal should be to be able to be \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"agnostic\"), \" to the form (which feels a little like what the Perceiver paper in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/generalised-neural-networks/\",\n    \"title\": \"Generalized Neural Networks\"\n  }, \"generalised-neural-networks\"), \" was trying to accomplish).\"), mdx(\"p\", null, \"What would that mean in the case of images? I quite liked the figure below, which talks about \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"semantic density\"), \". In some sense, they're different views of the same representation (though of course the image is the most \\\"complete\\\", and usually what we care about is starting from images; though one might also want to be able to learn the inverse mapping, from label to image).\"), mdx(\"figure\", {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"600px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/e8a5646f012bb6de88d8f22a86ac5384/ab98c/virtex.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"29.333333333333332%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAABrklEQVQY0x3MSU8TcQBA8fk6nrx68Gy88Am8mBj1gIaYiNEEY6xgJPGCEkvw4AUVkxqMwWC1FEpTYrpAN6csnelMSwe6/BlmaWda2j4j7/pLnnQiuhQODNS6yaHeonpis1dpkJU1DOGzX7OQ1Sb5vSqZgoJyZFI8NC4sV9KRy3VqTZfdvxWMloP0ai7IxOQTkuksr9/MsxaN02xbHLdtSvksgfExPr+fpSFcFO0IcdYlHo/zJ5mmeeaRKSoo1QYF+QCjIZBevpjkwc3rbERWmZ66R+jrMo5t0R+MEFqexYlLbC+NMwIsywK3xmrwFrHQNBi7fArHqLVMNLWM6zpI2dwm0egSNUOlJKeoaDKdTvdiUFVVZp8/ZnEhwP96PZ/9cpWKojH0HbKyjn7aoT8YoOs6nuchhZbfMjN1g0hshUd3r7IQfIrfGzAcnrOVSHPl2mVuPxyj1xtgmoLIRpK5mTsktr6RSOt4xXVOm8dkdnYQ7TZSKvWbn2sfyeSShFbmWY99pyUEju2SLhYIPLtPOPQB1+tjWTbnIwh/ecf25g98t0E99wunY9MWJp2uzz+CNpeUnsgw4QAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Comparison of pretraining tasks for learning visual representations\",\n    \"title\": \"Comparison of pretraining tasks for learning visual representations\",\n    \"src\": \"/static/e8a5646f012bb6de88d8f22a86ac5384/0a47e/virtex.png\",\n    \"srcSet\": [\"/static/e8a5646f012bb6de88d8f22a86ac5384/8a4e8/virtex.png 150w\", \"/static/e8a5646f012bb6de88d8f22a86ac5384/5a46d/virtex.png 300w\", \"/static/e8a5646f012bb6de88d8f22a86ac5384/0a47e/virtex.png 600w\", \"/static/e8a5646f012bb6de88d8f22a86ac5384/1cfc2/virtex.png 900w\", \"/static/e8a5646f012bb6de88d8f22a86ac5384/c1b63/virtex.png 1200w\", \"/static/e8a5646f012bb6de88d8f22a86ac5384/ab98c/virtex.png 2356w\"],\n    \"sizes\": \"(max-width: 600px) 100vw, 600px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Comparison of pretraining tasks for learning visual representations\"), \"\\n  \"), mdx(\"p\", null, \"It almost feels like some kind of ensemble, or crowd-sourcing problem, whereby image captioning can be thought of as the gold standard, providing a lot of semantic information, and the crops from contrastive learning much weaker and noisier \\\"labels\\\".\"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-desai2021virtex\"\n  }, \"Desai, K. & Johnson, J., 2021. Virtex: Learning visual representations from textual annotations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 11162\\u201311173.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-desai2021virtex\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/multi-modal learning/","title":"Multi-Modal Learning"}}]},"tagsOutbound":{"nodes":[{"frontmatter":{"title":"","tags":["machine_learning","deep_learning"]},"fields":{"slug":"/DALL-E2/","title":"DALL-E 2","lastUpdated":"4/27/2022","lastUpdatedAt":"2022-04-27T14:31:45.000Z","gitCreatedAt":"2022-04-27T14:31:45.000Z"}},{"frontmatter":{"title":"","tags":["self_supervised_learning","machine_learning","from_paper"]},"fields":{"slug":"/MoCo/","title":"Momentum Contrast for Unsupervised Visual Representation Learning","lastUpdated":"4/9/2022","lastUpdatedAt":"2022-04-09T10:57:18.000Z","gitCreatedAt":"2022-04-08T15:16:16.000Z"}},{"frontmatter":{"title":"","tags":["interpolation","statistics","machine_learning"]},"fields":{"slug":"/classification-vs-regression/","title":"Classification vs Regression","lastUpdated":"4/6/2022","lastUpdatedAt":"2022-04-06T00:52:19.000Z","gitCreatedAt":"2022-02-12T11:03:50.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning","from_paper"]},"fields":{"slug":"/dataset-bias/","title":"Dataset Bias","lastUpdated":"4/16/2022","lastUpdatedAt":"2022-04-16T07:10:21.000Z","gitCreatedAt":"2022-04-15T21:18:03.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","machine_learning","neural_tangent_kernel"]},"fields":{"slug":"/dataset-meta-learning-from-kernel-regression/","title":"Dataset Distillation","lastUpdated":"2/26/2022","lastUpdatedAt":"2022-02-26T13:00:00.000Z","gitCreatedAt":"2021-12-25T21:42:34.000Z"}},{"frontmatter":{"title":"","tags":["neural_networks","optimisation"]},"fields":{"slug":"/discretization-of-gradient-flow/","title":"Discretization of Gradient Flow","lastUpdated":"1/22/2022","lastUpdatedAt":"2022-01-22T10:54:29.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["xAI","machine_learning"]},"fields":{"slug":"/explainable-trees/","title":"Explainable Trees","lastUpdated":"4/15/2022","lastUpdatedAt":"2022-04-15T20:31:09.000Z","gitCreatedAt":"2022-04-15T20:31:09.000Z"}},{"frontmatter":{"title":"","tags":["neural_networks","biologically_inspired"]},"fields":{"slug":"/fast-weights/","title":"Fast Weights","lastUpdated":"2/4/2022","lastUpdatedAt":"2022-02-04T15:31:52.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["neural_tangent_kernel","machine_learning"]},"fields":{"slug":"/from-nerf-to-kernel-regression/","title":"From NERF to Kernel Regression","lastUpdated":"3/20/2022","lastUpdatedAt":"2022-03-20T12:15:24.000Z","gitCreatedAt":"2022-02-27T08:49:29.000Z"}},{"frontmatter":{"title":"","tags":["neural_networks","machine_learning"]},"fields":{"slug":"/generalised-neural-networks/","title":"Generalized Neural Networks","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T13:24:59.000Z","gitCreatedAt":"2022-01-22T10:54:29.000Z"}},{"frontmatter":{"title":"","tags":["from_article","neural_networks","graph_neural_networks"]},"fields":{"slug":"/graph-network-as-arbitrary-inductive-bias/","title":"Graph Network as Arbitrary Inductive Bias","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","computer_vision","attention","machine_learning"]},"fields":{"slug":"/how-do-vision-transformers-work/","title":"How Do Vision Transformers Work","lastUpdated":"3/11/2022","lastUpdatedAt":"2022-03-11T09:42:14.000Z","gitCreatedAt":"2022-03-11T09:08:13.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning"]},"fields":{"slug":"/invariant-risk-minimisation/","title":"Invariant Risk Minimisation","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning"]},"fields":{"slug":"/knowledge-distillation/","title":"Knowledge Distillation","lastUpdated":"1/4/2022","lastUpdatedAt":"2022-01-04T12:51:34.000Z","gitCreatedAt":"2021-12-23T12:17:23.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning","MLOps"]},"fields":{"slug":"/machine-learning-apis/","title":"Machine Learning APIs","lastUpdated":"3/1/2022","lastUpdatedAt":"2022-03-01T12:51:14.000Z","gitCreatedAt":"2022-03-01T12:14:49.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning","meta_learning"]},"fields":{"slug":"/meta-learning/","title":"Meta Learning","lastUpdated":"1/4/2022","lastUpdatedAt":"2022-01-04T21:27:53.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["self_supervised_learning","machine_learning","from_paper"]},"fields":{"slug":"/multiMAE/","title":"Multi MAE","lastUpdated":"4/8/2022","lastUpdatedAt":"2022-04-08T15:16:16.000Z","gitCreatedAt":"2022-04-08T15:16:16.000Z"}},{"frontmatter":{"title":"","tags":["neural_networks","from_paper"]},"fields":{"slug":"/neural-representations/","title":"Neural Representations","lastUpdated":"4/6/2022","lastUpdatedAt":"2022-04-06T00:52:19.000Z","gitCreatedAt":"2022-02-11T17:01:17.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning"]},"fields":{"slug":"/no-free-lunch/","title":"No Free Lunch","lastUpdated":"2/23/2022","lastUpdatedAt":"2022-02-23T16:00:05.000Z","gitCreatedAt":"2022-02-23T13:27:28.000Z"}},{"frontmatter":{"title":"","tags":["gui","machine_learning"]},"fields":{"slug":"/objection-detection-for-guis/","title":"Object Detection for GUI","lastUpdated":"1/4/2022","lastUpdatedAt":"2022-01-04T12:51:34.000Z","gitCreatedAt":"2021-12-24T10:27:07.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning"]},"fields":{"slug":"/self-supervised-learning/","title":"Self-supervised Learning","lastUpdated":"5/20/2022","lastUpdatedAt":"2022-05-20T08:21:07.000Z","gitCreatedAt":"2022-04-06T00:52:19.000Z"}},{"frontmatter":{"title":"","tags":["artificial_intelligence","machine_learning","psychology"]},"fields":{"slug":"/system-1-and-2/","title":"System 1 and 2","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning","neural_networks"]},"fields":{"slug":"/transformers/","title":"Transformers","lastUpdated":"1/4/2022","lastUpdatedAt":"2022-01-04T21:27:53.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","machine_learning","computer_vision","attention"]},"fields":{"slug":"/vision-transformers/","title":"Vision Transformers","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2022-01-16T10:24:03.000Z"}}]}},"pageContext":{"tags":["neural_networks","machine_learning"],"slug":"/generalised-neural-networks/","sidebarItems":[{"title":"","items":[{"title":"Recently Updated","url":"/latest/","collapse":true,"indent":false,"items":[{"title":"07-05: Text Recognition","url":"/text-recognition/"},{"title":"07-04: Causality in ML","url":"/causality/"},{"title":"07-04: CNNs","url":"/convolutional-neural-networks/"},{"title":"06-27: Generalisation Literature Review","url":"/generalisation-literature-review/"},{"title":"05-20: Multi-Modal Learning","url":"/multi-modal learning/"},{"title":"05-20: Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"05-10: Generalisation","url":"/generalisation/"},{"title":"05-06: Generalisation from Batch","url":"/generalisation-from-batch/"},{"title":"05-04: Fourier Features: A Curious Lens into Deep Learning","url":"/neural-paper/"},{"title":"04-27: DALL-E 2","url":"/DALL-E2/"}]}]},{"title":"Tags","items":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}]}],"tagsGroups":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}],"latestPosts":[{"fields":{"slug":"/text-recognition/","title":"Text Recognition","lastUpdatedAt":"2022-07-05T10:13:31.000Z","lastUpdated":"7/5/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/causality/","title":"Causality in ML","lastUpdatedAt":"2022-07-04T16:47:40.000Z","lastUpdated":"7/4/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/convolutional-neural-networks/","title":"CNNs","lastUpdatedAt":"2022-07-04T13:36:29.000Z","lastUpdated":"7/4/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/generalisation-literature-review/","title":"Generalisation Literature Review","lastUpdatedAt":"2022-06-27T15:06:07.000Z","lastUpdated":"6/27/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/multi-modal learning/","title":"Multi-Modal Learning","lastUpdatedAt":"2022-05-20T08:34:03.000Z","lastUpdated":"5/20/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/self-supervised-learning/","title":"Self-supervised Learning","lastUpdatedAt":"2022-05-20T08:21:07.000Z","lastUpdated":"5/20/2022"},"frontmatter":{"draft":false,"tags":["machine_learning"]}},{"fields":{"slug":"/generalisation/","title":"Generalisation","lastUpdatedAt":"2022-05-10T07:20:45.000Z","lastUpdated":"5/10/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/generalisation-from-batch/","title":"Generalisation from Batch","lastUpdatedAt":"2022-05-06T21:55:47.000Z","lastUpdated":"5/6/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/neural-paper/","title":"Fourier Features: A Curious Lens into Deep Learning","lastUpdatedAt":"2022-05-04T10:36:45.000Z","lastUpdated":"5/4/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/DALL-E2/","title":"DALL-E 2","lastUpdatedAt":"2022-04-27T14:31:45.000Z","lastUpdated":"4/27/2022"},"frontmatter":{"draft":false,"tags":["machine_learning","deep_learning"]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}