{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/dataset-meta-learning-from-kernel-regression/",
    "result": {"data":{"mdx":{"id":"07c90440-fe8c-5ac9-a8cf-5fb70753b856","tableOfContents":{"items":[{"url":"#dataset-distillation","title":"Dataset Distillation"}]},"fields":{"title":"Dataset Distillation","slug":"/dataset-meta-learning-from-kernel-regression/","url":"https://deepmind.vercel.app/dataset-meta-learning-from-kernel-regression/","editUrl":"https://github.com/dfeng/notes/tree/main/dataset-meta-learning-from-kernel-regression.md","lastUpdatedAt":"2022-02-26T13:00:00.000Z","lastUpdated":"2/26/2022","gitCreatedAt":"2021-12-25T21:42:34.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":["from_paper","machine_learning","neural_tangent_kernel"],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"from_paper\", \"machine_learning\", \"neural_tangent_kernel\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"dataset-distillation\"\n  }, \"Dataset Distillation\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"src: \", \"(Nguyen et al., 2021)\", mdx(\"sup\", {\n    parentName: \"li\",\n    \"id\": \"fnref-nguyen_dataset_2021\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-nguyen_dataset_2021\",\n    \"className\": \"footnote-ref\"\n  }, \"nguyen_dataset_2021\")), mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://rosanneliu.com/dlctfs/dlct_210730.pdf\"\n  }, \"slides\"))))), mdx(\"p\", null, \"You have \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/knowledge-distillation/\",\n    \"title\": \"Knowledge Distillation\"\n  }, \"knowledge-distillation\"), \", the goal of which is to compress models down while retaining the same performance. A similar but orthogonal problem is to compress data down while retaining the same \\\"performance\\\" (an algorithm trained on this compressed dataset would reach the same performance as if it were trained on the original dataset).\"), mdx(\"p\", null, \"One (classic) approach is [\", \"[coresets]\", \"], which seek to find a subset of the full dataset such that queries have approximately the same answer on both datasets. These kinds of summarisation techniques can also be framed in terms of optimising a submodular function (submodularity being the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"discrete\"), \" analog of convexity), and there is a whole field of applying this topic to machine learning. Finally, one can use (very classic) unsupervised methods like \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"k\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"k\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.69444em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.03148em\"\n    }\n  }, \"k\"))))), \"-means clustering to form cluster centers that can be used as representative samples. A problem with the first two methods is that the distilled dataset must be a subset, which might be restrictive (though sometimes being restrictive is a good thing?). The general problem with these aforementioned methods is that they are usually heuristic-based; as such, there are no guarantees on downstream tasks (validation loss) (again, however, this might actually be a good thing, in that we aren't too focused on a particular task).\"), mdx(\"p\", null, \"Dataset distillation solves these problems by turning this into a learning problem, where we actually learn a new dataset so that it does well in the downstream task (i.e. these are the \\\"parameters\\\" that we're going to optimise over). This new dataset is not a subset of the original dataset (in theory it could be, but as we'll see they end up being very different).\"), mdx(\"p\", null, \"I feel like there's something interesting here for the psychologists. They're always looking to find the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"archetypal\"), \" image for a class.\"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-nguyen_dataset_2021\"\n  }, \"Nguyen, T., Chen, Z. & Lee, J., 2021. Dataset Meta-Learning from Kernel Ridge-Regression. arXiv:2011.00050 [cs, stat]. Available at: http://arxiv.org/abs/2011.00050 [Accessed December 25, 2021].\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-nguyen_dataset_2021\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\ntags:\n  - from_paper\n  - machine_learning\n  - neural_tangent_kernel\n---\n\n# Dataset Distillation\n\n - src: [@nguyen_dataset_2021]\n\t - [slides](https://rosanneliu.com/dlctfs/dlct_210730.pdf)\n\nYou have [[knowledge-distillation]], the goal of which is to compress models down while retaining the same performance. A similar but orthogonal problem is to compress data down while retaining the same \"performance\" (an algorithm trained on this compressed dataset would reach the same performance as if it were trained on the original dataset).\n\nOne (classic) approach is [[coresets]], which seek to find a subset of the full dataset such that queries have approximately the same answer on both datasets. These kinds of summarisation techniques can also be framed in terms of optimising a submodular function (submodularity being the *discrete* analog of convexity), and there is a whole field of applying this topic to machine learning. Finally, one can use (very classic) unsupervised methods like $k$-means clustering to form cluster centers that can be used as representative samples. A problem with the first two methods is that the distilled dataset must be a subset, which might be restrictive (though sometimes being restrictive is a good thing?). The general problem with these aforementioned methods is that they are usually heuristic-based; as such, there are no guarantees on downstream tasks (validation loss) (again, however, this might actually be a good thing, in that we aren't too focused on a particular task).\n\nDataset distillation solves these problems by turning this into a learning problem, where we actually learn a new dataset so that it does well in the downstream task (i.e. these are the \"parameters\" that we're going to optimise over). This new dataset is not a subset of the original dataset (in theory it could be, but as we'll see they end up being very different).\n\nI feel like there's something interesting here for the psychologists. They're always looking to find the *archetypal* image for a class.\n\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\n[knowledge-distillation]: knowledge-distillation.md \"Knowledge Distillation\"\n[//end]: # \"Autogenerated link references\"","excerpt":"Dataset Distillation src:  @nguyen_dataset_2021 slides You have [ knowledge-distillation ], the goal of which is to compress models down whâ€¦","outboundReferences":[{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"machine_learning\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"knowledge-distillation\"\n  }, \"Knowledge Distillation\"), mdx(\"p\", null, \"As a constructive example, think of two similar classifications (two types of breeds of dogs). With one-hot encoding, these are orthogonal, and each class is essentially equivalent/exchangeable. However there's actually more structure to these classifications (you can imagine them being in some embedding space, and the dog classes should be closer together). I guess the phrase is \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"label similarity\"), \".\"), mdx(\"p\", null, \"The softmax probabilities is (hopefully) a proxy for this. So, in part, the student gets the shortcut of learning these class representations, but also conceivably it does not have the capacity to \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"learn\"), \" these subtleties, though it is able to mimic it.\"), mdx(\"p\", null, \"Does Knowledge Distillation really work? \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/pdf/2106.05945.pdf\"\n  }, \"arXiv\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  })), mdx(\"p\", null, \"KD as Semi-parametric Inference \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=dEE3-g_8dWo\"\n  }, \"Youtube\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  })), mdx(\"p\", null, \"Many weird and curious results in this field:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"It turns out that if you do self-distillation (i.e. the student is the teacher, there's a Buddhist joke here somewhere), then the student will oftentimes outperform the teacher. \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/1805.04770\"\n  }, \"arXiv\"), \".\")));\n}\n;\nMDXContent.isMDXComponent = true;","fields":{"slug":"/knowledge-distillation/","title":"Knowledge Distillation","shouldShowTitle":false}}],"inboundReferences":[]},"tagsOutbound":{"nodes":[{"frontmatter":{"title":"","tags":["machine_learning","deep_learning"]},"fields":{"slug":"/DALL-E2/","title":"DALL-E 2","lastUpdated":"4/27/2022","lastUpdatedAt":"2022-04-27T14:31:45.000Z","gitCreatedAt":"2022-04-27T14:31:45.000Z"}},{"frontmatter":{"title":"","tags":["self_supervised_learning","machine_learning","from_paper"]},"fields":{"slug":"/MoCo/","title":"Momentum Contrast for Unsupervised Visual Representation Learning","lastUpdated":"4/9/2022","lastUpdatedAt":"2022-04-09T10:57:18.000Z","gitCreatedAt":"2022-04-08T15:16:16.000Z"}},{"frontmatter":{"title":"","tags":["from_paper"]},"fields":{"slug":"/a-universal-law-of-robustness-via-isoperimetry/","title":"A Universal Law of Robustness via Isoperimetry","lastUpdated":"4/16/2022","lastUpdatedAt":"2022-04-16T07:10:21.000Z","gitCreatedAt":"2022-04-15T21:18:03.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","lit_review","interpolation"]},"fields":{"slug":"/benign-overfitting-in-linear-regression/","title":"Benign Overfitting in Linear Regression","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["from_paper"]},"fields":{"slug":"/can-you-learn-an-algorithm/","title":"Can You Learn an Algorithm","lastUpdated":"3/24/2022","lastUpdatedAt":"2022-03-24T17:13:26.000Z","gitCreatedAt":"2021-12-23T11:27:19.000Z"}},{"frontmatter":{"title":"","tags":["interpolation","statistics","machine_learning"]},"fields":{"slug":"/classification-vs-regression/","title":"Classification vs Regression","lastUpdated":"4/6/2022","lastUpdatedAt":"2022-04-06T00:52:19.000Z","gitCreatedAt":"2022-02-12T11:03:50.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning","from_paper"]},"fields":{"slug":"/dataset-bias/","title":"Dataset Bias","lastUpdated":"4/16/2022","lastUpdatedAt":"2022-04-16T07:10:21.000Z","gitCreatedAt":"2022-04-15T21:18:03.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","machine_learning","neural_tangent_kernel"]},"fields":{"slug":"/dataset-meta-learning-from-kernel-regression/","title":"Dataset Distillation","lastUpdated":"2/26/2022","lastUpdatedAt":"2022-02-26T13:00:00.000Z","gitCreatedAt":"2021-12-25T21:42:34.000Z"}},{"frontmatter":{"title":"","tags":["from_paper"]},"fields":{"slug":"/embeddings-cant-possibly-be-right/","title":"Embeddings Can't Possibly Be Right","lastUpdated":"2/13/2022","lastUpdatedAt":"2022-02-13T17:46:16.000Z","gitCreatedAt":"2022-02-13T10:27:23.000Z"}},{"frontmatter":{"title":"","tags":["xAI","machine_learning"]},"fields":{"slug":"/explainable-trees/","title":"Explainable Trees","lastUpdated":"4/15/2022","lastUpdatedAt":"2022-04-15T20:31:09.000Z","gitCreatedAt":"2022-04-15T20:31:09.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","lit_review","gradient_descent","optimisation","regularization"]},"fields":{"slug":"/exponential-learning-rates/","title":"Exponential Learning Rates","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["neural_tangent_kernel","machine_learning"]},"fields":{"slug":"/from-nerf-to-kernel-regression/","title":"From NERF to Kernel Regression","lastUpdated":"3/20/2022","lastUpdatedAt":"2022-03-20T12:15:24.000Z","gitCreatedAt":"2022-02-27T08:49:29.000Z"}},{"frontmatter":{"title":"","tags":["neural_networks","machine_learning"]},"fields":{"slug":"/generalised-neural-networks/","title":"Generalized Neural Networks","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T13:24:59.000Z","gitCreatedAt":"2022-01-22T10:54:29.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","computer_vision","attention","machine_learning"]},"fields":{"slug":"/how-do-vision-transformers-work/","title":"How Do Vision Transformers Work","lastUpdated":"3/11/2022","lastUpdatedAt":"2022-03-11T09:42:14.000Z","gitCreatedAt":"2022-03-11T09:08:13.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning"]},"fields":{"slug":"/invariant-risk-minimisation/","title":"Invariant Risk Minimisation","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning"]},"fields":{"slug":"/knowledge-distillation/","title":"Knowledge Distillation","lastUpdated":"1/4/2022","lastUpdatedAt":"2022-01-04T12:51:34.000Z","gitCreatedAt":"2021-12-23T12:17:23.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","nlp","lit_review","neuroscience"]},"fields":{"slug":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/","title":"Learning as the Unsupervised Alignment of Conceptual Systems","lastUpdated":"4/16/2022","lastUpdatedAt":"2022-04-16T07:10:21.000Z","gitCreatedAt":"2022-04-15T21:18:03.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","causal_inference"]},"fields":{"slug":"/learning-dags/","title":"Learning DAGs","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning","MLOps"]},"fields":{"slug":"/machine-learning-apis/","title":"Machine Learning APIs","lastUpdated":"3/1/2022","lastUpdatedAt":"2022-03-01T12:51:14.000Z","gitCreatedAt":"2022-03-01T12:14:49.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning","meta_learning"]},"fields":{"slug":"/meta-learning/","title":"Meta Learning","lastUpdated":"1/4/2022","lastUpdatedAt":"2022-01-04T21:27:53.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["self_supervised_learning","machine_learning","from_paper"]},"fields":{"slug":"/multiMAE/","title":"Multi MAE","lastUpdated":"4/8/2022","lastUpdatedAt":"2022-04-08T15:16:16.000Z","gitCreatedAt":"2022-04-08T15:16:16.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","psychology"]},"fields":{"slug":"/multidimensional-mental-representations-of-natural-objects/","title":"Multidimensional Mental Representations of Natural Objects","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2021-12-24T11:18:15.000Z"}},{"frontmatter":{"title":"","tags":["neural_networks","from_paper"]},"fields":{"slug":"/neural-representations/","title":"Neural Representations","lastUpdated":"4/6/2022","lastUpdatedAt":"2022-04-06T00:52:19.000Z","gitCreatedAt":"2022-02-11T17:01:17.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning"]},"fields":{"slug":"/no-free-lunch/","title":"No Free Lunch","lastUpdated":"2/23/2022","lastUpdatedAt":"2022-02-23T16:00:05.000Z","gitCreatedAt":"2022-02-23T13:27:28.000Z"}},{"frontmatter":{"title":"","tags":["from_paper"]},"fields":{"slug":"/non-deep-networks/","title":"Non-deep Networks","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2021-12-23T11:27:19.000Z"}},{"frontmatter":{"title":"","tags":["gui","machine_learning"]},"fields":{"slug":"/objection-detection-for-guis/","title":"Object Detection for GUI","lastUpdated":"1/4/2022","lastUpdatedAt":"2022-01-04T12:51:34.000Z","gitCreatedAt":"2021-12-24T10:27:07.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","overparameterization"]},"fields":{"slug":"/overparameterized-regression/","title":"Overparameterized Regression","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning"]},"fields":{"slug":"/self-supervised-learning/","title":"Self-supervised Learning","lastUpdated":"5/20/2022","lastUpdatedAt":"2022-05-20T08:21:07.000Z","gitCreatedAt":"2022-04-06T00:52:19.000Z"}},{"frontmatter":{"title":"","tags":["from_paper"]},"fields":{"slug":"/spectral-bias/","title":"On the Spectral Bias of Neural Networks","lastUpdated":"4/17/2022","lastUpdatedAt":"2022-04-17T20:39:26.000Z","gitCreatedAt":"2022-04-15T08:46:07.000Z"}},{"frontmatter":{"title":"","tags":["from_paper"]},"fields":{"slug":"/stand-alone-self-attention-in-vision-models/","title":"Stand-Alone Self-Attention in Vision Models","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2021-12-23T11:27:19.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","society","research"]},"fields":{"slug":"/stewardship-of-global-collective-beahvior/","title":"Stewardship of Global Collective Behaviour","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["artificial_intelligence","machine_learning","psychology"]},"fields":{"slug":"/system-1-and-2/","title":"System 1 and 2","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["machine_learning","neural_networks"]},"fields":{"slug":"/transformers/","title":"Transformers","lastUpdated":"1/4/2022","lastUpdatedAt":"2022-01-04T21:27:53.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","statistics","research","classic_papers"]},"fields":{"slug":"/two-cultures/","title":"Two Cultures","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["research","nlp","from_paper"]},"fields":{"slug":"/unsupervised-language-translation/","title":"Unsupervised Language Translation","lastUpdated":"4/16/2022","lastUpdatedAt":"2022-04-16T07:10:21.000Z","gitCreatedAt":"2022-04-15T20:31:09.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","machine_learning","computer_vision","attention"]},"fields":{"slug":"/vision-transformers/","title":"Vision Transformers","lastUpdated":"1/29/2022","lastUpdatedAt":"2022-01-29T14:49:40.000Z","gitCreatedAt":"2022-01-16T10:24:03.000Z"}}]}},"pageContext":{"tags":["from_paper","machine_learning","neural_tangent_kernel"],"slug":"/dataset-meta-learning-from-kernel-regression/","sidebarItems":[{"title":"","items":[{"title":"Recently Updated","url":"/latest/","collapse":true,"indent":false,"items":[{"title":"10-10: Generalisation-Theory","url":"/generalisation-theory/"},{"title":"10-05: Generalisation Paper","url":"/generalisation-paper/"},{"title":"09-24: Generative Models","url":"/generative-models/"},{"title":"09-23: Score-Based-Models","url":"/score-based-models/"},{"title":"09-23: Diffusion-Models","url":"/diffusion-models/"},{"title":"07-29: Test Augmentation","url":"/test-augmentation/"},{"title":"07-28: Multi-Modal Learning","url":"/multi-modal-learning/"},{"title":"07-27: Text Recognition","url":"/text-recognition/"},{"title":"07-19: Sequence Learning","url":"/sequence-learning/"},{"title":"07-07: Text Recognition Literature Review","url":"/text-recognition-review/"}]}]},{"title":"Tags","items":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}]}],"tagsGroups":[{"title":"MLOps","type":"tag","url":"/tags/ml-ops/","items":[{"title":"Machine Learning APIs","url":"/machine-learning-apis/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Artificial Generalised Intelligence","url":"/artificial-generalised-intelligence/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"A Universal Law of Robustness via Isoperimetry","url":"/a-universal-law-of-robustness-via-isoperimetry/"},{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Embeddings Can't Possibly Be Right","url":"/embeddings-cant-possibly-be-right/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"On the Spectral Bias of Neural Networks","url":"/spectral-bias/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Slack Bot","url":"/slack-bot/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit Regularisation","url":"/implicit-regularisation/"}]},{"title":"interpolation","type":"tag","url":"/tags/interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Ideas Around Interpolation","url":"/ideas-around-interpolation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"DALL-E 2","url":"/DALL-E2/"},{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dataset Bias","url":"/dataset-bias/"},{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Explainable Trees","url":"/explainable-trees/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"How Do Vision Transformers Work","url":"/how-do-vision-transformers-work/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Machine Learning APIs","url":"/machine-learning-apis/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Multi MAE","url":"/multiMAE/"},{"title":"No Free Lunch","url":"/no-free-lunch/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"Self-supervised Learning","url":"/self-supervised-learning/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Efficient Markets and Data","url":"/efficient-markets-and-data/"},{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"networks","type":"tag","url":"/tags/networks/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Noisy Networks","url":"/noisy-networks/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Fast Weights","url":"/fast-weights/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Neural Representations","url":"/neural-representations/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Distillation","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"From NERF to Kernel Regression","url":"/from-nerf-to-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus For Brain Computation","url":"/calculus-for-brain-computation/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Learning as the Unsupervised Alignment of Conceptual Systems","url":"/learning-as-the-unsupervised-alignment-of-conceptual-systems/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"reinforcement_learning","type":"tag","url":"/tags/reinforcement-learning/","items":[{"title":"World Models","url":"/world-models/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"},{"title":"Unsupervised Language Translation","url":"/unsupervised-language-translation/"}]},{"title":"self_supervised_learning","type":"tag","url":"/tags/self-supervised-learning/","items":[{"title":"Momentum Contrast for Unsupervised Visual Representation Learning","url":"/MoCo/"},{"title":"Multi MAE","url":"/multiMAE/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Classification vs Regression","url":"/classification-vs-regression/"},{"title":"Dynamic Graph Models","url":"/dynamic-graph-models/"},{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"Explainable Trees","url":"/explainable-trees/"}]}],"latestPosts":[{"fields":{"slug":"/generalisation-theory/","title":"Generalisation-Theory","lastUpdatedAt":"2022-10-10T17:44:05.000Z","lastUpdated":"10/10/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/generalisation-paper/","title":"Generalisation Paper","lastUpdatedAt":"2022-10-05T08:06:27.000Z","lastUpdated":"10/5/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/generative-models/","title":"Generative Models","lastUpdatedAt":"2022-09-24T18:20:55.000Z","lastUpdated":"9/24/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/score-based-models/","title":"Score-Based-Models","lastUpdatedAt":"2022-09-23T15:57:48.000Z","lastUpdated":"9/23/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/diffusion-models/","title":"Diffusion-Models","lastUpdatedAt":"2022-09-23T14:44:25.000Z","lastUpdated":"9/23/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/test-augmentation/","title":"Test Augmentation","lastUpdatedAt":"2022-07-29T16:14:51.000Z","lastUpdated":"7/29/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/multi-modal-learning/","title":"Multi-Modal Learning","lastUpdatedAt":"2022-07-28T22:29:47.000Z","lastUpdated":"7/28/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/text-recognition/","title":"Text Recognition","lastUpdatedAt":"2022-07-27T21:05:55.000Z","lastUpdated":"7/27/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/sequence-learning/","title":"Sequence Learning","lastUpdatedAt":"2022-07-19T11:13:08.000Z","lastUpdated":"7/19/2022"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/text-recognition-review/","title":"Text Recognition Literature Review","lastUpdatedAt":"2022-07-07T13:39:00.000Z","lastUpdated":"7/7/2022"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}