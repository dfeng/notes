{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/objection-detection-for-guis/",
    "result": {"data":{"mdx":{"id":"8472b311-876a-55ab-bbee-515e04fde6d4","tableOfContents":{"items":[{"url":"#object-detection-for-gui","title":"Object Detection for GUI","items":[{"url":"#problems","title":"Problems"}]}]},"fields":{"title":"Object Detection for GUI","slug":"/objection-detection-for-guis/","url":"https://dfeng.github.io/notes/notes/objection-detection-for-guis/","editUrl":"https://github.com/dfeng/notes/tree/main/objection-detection-for-guis.md","lastUpdatedAt":"2021-12-24T10:27:07.000Z","lastUpdated":"12/24/2021","gitCreatedAt":"2021-12-24T10:27:07.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":["gui","machine learning"],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"gui\", \"machine learning\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"object-detection-for-gui\"\n  }, \"Object Detection for GUI\"), mdx(\"h2\", {\n    \"id\": \"problems\"\n  }, \"Problems\"), mdx(\"p\", null, \"Large in-class variance and similarity between classes: basically, a very difficult problem!\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Large in-class variance:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"style is at the whim of the designer/application.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"in general (interestingly), each data point has the same style, but across samples you have nothing\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"High cross-class similarity:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"key here is that sometimes the difference between two GUIs is something very small. that being said, this is more about classifying different types of GUIs, which we don't really do right now.\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Packed scenes:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"close quarters, dense \\u2013 in stark contrast to natural object detection problems\")))), mdx(\"p\", null, \"I think it's also important to highlight the difference between GUIs and natural images, because that's exactly where we can improve (or even cross-pollinate).\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"sharp, pixel based (plus some shadows, but all computer generated)\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"close quarter, dense\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"no common style per class\")), mdx(\"img\", {\n    \"src\": \"https://i.imgur.com/dPDbZRP.png\",\n    \"alt\": \"examples\"\n  }), mdx(\"img\", {\n    \"src\": \"https://i.imgur.com/N1pFCLT.png\",\n    \"alt\": \"table\"\n  }));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\ntags:\n  - gui\n  - machine learning\n---\n\n# Object Detection for GUI\n\n## Problems\n\nLarge in-class variance and similarity between classes: basically, a very difficult problem!\n\n - Large in-class variance:\n   - style is at the whim of the designer/application.\n   - in general (interestingly), each data point has the same style, but across samples you have nothing\n - High cross-class similarity:\n   - key here is that sometimes the difference between two GUIs is something very small. that being said, this is more about classifying different types of GUIs, which we don't really do right now.\n - Packed scenes:\n   - close quarters, dense – in stark contrast to natural object detection problems\n\nI think it's also important to highlight the difference between GUIs and natural images, because that's exactly where we can improve (or even cross-pollinate).\n\n1. sharp, pixel based (plus some shadows, but all computer generated)\n2. close quarter, dense\n3. no common style per class\n\n![examples](https://i.imgur.com/dPDbZRP.png)\n\n\n\n![table](https://i.imgur.com/N1pFCLT.png)\n\n","excerpt":"Object Detection for GUI Problems Large in-class variance and similarity between classes: basically, a very difficult problem! Large in-cla…","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[{"frontmatter":{"title":"","tags":["gui","machine learning"]},"fields":{"slug":"/objection-detection-for-guis/","title":"Object Detection for GUI","lastUpdated":"12/24/2021","lastUpdatedAt":"2021-12-24T10:27:07.000Z","gitCreatedAt":"2021-12-24T10:27:07.000Z"}}]}},"pageContext":{"tags":["gui","machine learning"],"slug":"/objection-detection-for-guis/","sidebarItems":[{"title":"","items":[{"title":"Recently Updated","url":"/latest/","collapse":true,"indent":false,"items":[{"title":"12-24: Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"12-24: Triplet Loss","url":"/triplet-loss/"},{"title":"12-24: Perception","url":"/kahneman-neurips-perception/"},{"title":"12-24: Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"12-24: 2021-12-24","url":"/journal/2021-12-24/"},{"title":"12-24: Artifactual Neural Network","url":"/"},{"title":"12-23: Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"12-23: Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"12-23: Non-deep Networks","url":"/non-deep-networks/"},{"title":"12-23: Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"}]}]},{"title":"Tags","items":[{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"}]},{"title":"journal","type":"tag","url":"/tags/journal/","items":[{"title":"2021-12-24","url":"/journal/2021-12-24/"}]},{"title":"machine learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"paper","type":"tag","url":"/tags/paper/","items":[{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"}]}]}],"tagsGroups":[{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"}]},{"title":"journal","type":"tag","url":"/tags/journal/","items":[{"title":"2021-12-24","url":"/journal/2021-12-24/"}]},{"title":"machine learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"paper","type":"tag","url":"/tags/paper/","items":[{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"}]}],"latestPosts":[{"fields":{"slug":"/multidimensional-mental-representations-of-natural-objects/","title":"Multidimensional Mental Representations of Natural Objects","lastUpdatedAt":"2021-12-24T18:09:30.000Z","lastUpdated":"12/24/2021"},"frontmatter":{"draft":false,"tags":["paper","psychology"]}},{"fields":{"slug":"/triplet-loss/","title":"Triplet Loss","lastUpdatedAt":"2021-12-24T18:09:30.000Z","lastUpdated":"12/24/2021"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/kahneman-neurips-perception/","title":"Perception","lastUpdatedAt":"2021-12-24T10:27:07.000Z","lastUpdated":"12/24/2021"},"frontmatter":{"draft":false,"tags":["neurips","psychology"]}},{"fields":{"slug":"/objection-detection-for-guis/","title":"Object Detection for GUI","lastUpdatedAt":"2021-12-24T10:27:07.000Z","lastUpdated":"12/24/2021"},"frontmatter":{"draft":false,"tags":["gui","machine learning"]}},{"fields":{"slug":"/journal/2021-12-24/","title":"2021-12-24","lastUpdatedAt":"2021-12-24T10:27:07.000Z","lastUpdated":"12/24/2021"},"frontmatter":{"draft":false,"tags":["journal"]}},{"fields":{"slug":"/","title":"Artifactual Neural Network","lastUpdatedAt":"2021-12-24T08:23:18.000Z","lastUpdated":"12/24/2021"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/knowledge-distillation/","title":"Knowledge Distillation","lastUpdatedAt":"2021-12-23T12:17:23.000Z","lastUpdated":"12/23/2021"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/can-you-learn-an-algorithm/","title":"Can You Learn an Algorithm","lastUpdatedAt":"2021-12-23T11:27:19.000Z","lastUpdated":"12/23/2021"},"frontmatter":{"draft":false,"tags":["paper"]}},{"fields":{"slug":"/non-deep-networks/","title":"Non-deep Networks","lastUpdatedAt":"2021-12-23T11:27:19.000Z","lastUpdated":"12/23/2021"},"frontmatter":{"draft":false,"tags":["paper"]}},{"fields":{"slug":"/stand-alone-self-attention-in-vision-models/","title":"Stand-Alone Self-Attention in Vision Models","lastUpdatedAt":"2021-12-23T11:27:19.000Z","lastUpdated":"12/23/2021"},"frontmatter":{"draft":false,"tags":["paper"]}}]}},
    "staticQueryHashes": ["2320115945","2650345336","3495835395","451533639"]}