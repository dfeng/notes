{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/on-optimisation-in-matrix-completion/",
    "result": {"data":{"mdx":{"id":"0f7b5f7c-7ca3-598b-b4d8-194896e6f56b","tableOfContents":{"items":[{"url":"#on-optimisation-in-matrix-completion","title":"On Optimisation in Matrix Completion","items":[{"url":"#non-convex","title":"Non-Convex"}]}]},"fields":{"title":"On Optimisation in Matrix Completion","slug":"/on-optimisation-in-matrix-completion/","url":"https://dfeng.github.io/notes/notes/on-optimisation-in-matrix-completion/","editUrl":"https://github.com/dfeng/notes/tree/main/on-optimisation-in-matrix-completion.md","lastUpdatedAt":"2022-01-12T12:14:44.000Z","lastUpdated":"1/12/2022","gitCreatedAt":"2022-01-12T12:14:44.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":["optimisation"],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"tags\": [\"optimisation\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"on-optimisation-in-matrix-completion\"\n  }, \"On Optimisation in Matrix Completion\"), mdx(\"p\", null, \"Statisticians get their first taste of optimisation when they learn about penalised linear regression:\"), mdx(\"div\", {\n    \"className\": \"math math-display\"\n  }, mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"katex-error\",\n    \"title\": \"ParseError: KaTeX parse error: No such environment: align* at position 7: \\\\begin{̲a̲l̲i̲g̲n̲*̲}̲ \\\\min_{\\\\beta} \\\\…\",\n    \"style\": {\n      \"color\": \"#cc0000\"\n    }\n  }, \"\\\\begin{align*} \\\\min_{\\\\beta} \\\\|Y - X \\\\beta\\\\|_2^2 + \\\\lambda\\\\|\\\\beta\\\\|_p. \\\\end{align*}\")), mdx(\"p\", null, \"It turns out that there's an equivalent formulation (as a constrained minimisation) that provides a little more intuition:\"), mdx(\"div\", {\n    \"className\": \"math math-display\"\n  }, mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"katex-error\",\n    \"title\": \"ParseError: KaTeX parse error: No such environment: align* at position 7: \\\\begin{̲a̲l̲i̲g̲n̲*̲}̲ \\\\min \\\\|Y - X \\\\…\",\n    \"style\": {\n      \"color\": \"#cc0000\"\n    }\n  }, \"\\\\begin{align*} \\\\min \\\\|Y - X \\\\beta\\\\|_2^2 \\\\text{ s.t. } \\\\|\\\\beta\\\\|_p \\\\leq s, \\\\end{align*}\")), mdx(\"img\", {\n    \"src\": \"https://online.stat.psu.edu/onlinecourses/sites/stat508/files/lesson05/image_09.gif\",\n    \"alt\": \"The OG image.\"\n  }), mdx(\"p\", null, \"where there is a one-to-one relation between \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"\\u03BB\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\lambda\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.69444em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"\\u03BB\"))))), \" and \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"s\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"s\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.43056em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"s\"))))), \". This different view provides a geometric interpretation: depending on the geometry induced by the \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"l\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"p\"))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"l_p\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.980548em\",\n      \"verticalAlign\": \"-0.286108em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\",\n    \"style\": {\n      \"marginRight\": \"0.01968em\"\n    }\n  }, \"l\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.15139200000000003em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.5500000000000003em\",\n      \"marginLeft\": \"-0.01968em\",\n      \"marginRight\": \"0.05em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.7em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\"\n  }, \"p\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.286108em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))))))), \" ball that is the constraint set, you're going to get different kinds of solutions.\"), mdx(\"p\", null, \"Note that the above equivalence is exact only when the loss and the penalty are both convex. In the [\", \"[matrix-completion]\", \"] setting, with our penalty, this is no longer the case.\"), mdx(\"p\", null, \"The (classical) convex program \", \"(Candes & Recht, 2009)\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-Candes:2009kj\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-Candes:2009kj\",\n    \"className\": \"footnote-ref\"\n  }, \"Candes:2009kj\")), \" is given by:\"), mdx(\"div\", {\n    \"className\": \"math math-display\"\n  }, mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"katex-error\",\n    \"title\": \"ParseError: KaTeX parse error: No such environment: align* at position 7: \\\\begin{̲a̲l̲i̲g̲n̲*̲}̲ \\\\min \\\\|W\\\\|_\\\\st…\",\n    \"style\": {\n      \"color\": \"#cc0000\"\n    }\n  }, \"\\\\begin{align*} \\\\min \\\\|W\\\\|_\\\\star \\\\text{ s.t. } \\\\|\\\\mathcal{A}(W) - y \\\\|_2^2 \\\\leq \\\\epsilon, \\\\end{align*}\")), mdx(\"p\", null, \"where setting \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\"\n  }, \"\\u03F5\"), mdx(\"mo\", {\n    parentName: \"mrow\"\n  }, \"=\"), mdx(\"mn\", {\n    parentName: \"mrow\"\n  }, \"0\")), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\epsilon = 0\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.43056em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal\"\n  }, \"\\u03F5\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mrel\"\n  }, \"=\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mspace\",\n    \"style\": {\n      \"marginRight\": \"0.2777777777777778em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"0.64444em\",\n      \"verticalAlign\": \"0em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, \"0\"))))), \" reduces to the noise-less setting. The more recent development using a penalised linear model is given by:\"), mdx(\"div\", {\n    \"className\": \"math math-display\"\n  }, mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"katex-error\",\n    \"title\": \"ParseError: KaTeX parse error: No such environment: align* at position 7: \\\\begin{̲a̲l̲i̲g̲n̲*̲}̲ \\\\min_{W} \\\\| \\\\m…\",\n    \"style\": {\n      \"color\": \"#cc0000\"\n    }\n  }, \"\\\\begin{align*} \\\\min_{W} \\\\| \\\\mathcal{A}(W) - y \\\\|_2^2 + \\\\lambda \\\\|W\\\\|_{\\\\star} \\\\end{align*}\")), mdx(\"p\", null, \"Since they're both convex, you have equivalence just like for the Lasso.\", mdx(\"sup\", {\n    parentName: \"p\",\n    \"id\": \"fnref-1\"\n  }, mdx(\"a\", {\n    parentName: \"sup\",\n    \"href\": \"#fn-1\",\n    \"className\": \"footnote-ref\"\n  }, \"1\"))), mdx(\"h2\", {\n    \"id\": \"non-convex\"\n  }, \"Non-Convex\"), mdx(\"p\", null, \"What happens when we move to non-convex penalties though? Then, I think what you have is a \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"duality gap\"), \" (I could be wrong). If we use our penalty \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-mathml\"\n  }, mdx(\"math\", {\n    parentName: \"span\",\n    \"xmlns\": \"http://www.w3.org/1998/Math/MathML\"\n  }, mdx(\"semantics\", {\n    parentName: \"math\"\n  }, mdx(\"mrow\", {\n    parentName: \"semantics\"\n  }, mdx(\"mfrac\", {\n    parentName: \"mrow\"\n  }, mdx(\"mrow\", {\n    parentName: \"mfrac\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"normal\"\n  }, \"\\u2225\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"W\"), mdx(\"mo\", {\n    parentName: \"msub\",\n    \"lspace\": \"0em\",\n    \"rspace\": \"0em\"\n  }, \"\\u22C6\"))), mdx(\"mrow\", {\n    parentName: \"mfrac\"\n  }, mdx(\"mi\", {\n    parentName: \"mrow\",\n    \"mathvariant\": \"normal\"\n  }, \"\\u2225\"), mdx(\"msub\", {\n    parentName: \"mrow\"\n  }, mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"W\"), mdx(\"mi\", {\n    parentName: \"msub\"\n  }, \"F\"))))), mdx(\"annotation\", {\n    parentName: \"semantics\",\n    \"encoding\": \"application/x-tex\"\n  }, \"\\\\frac{\\\\|{W}_{\\\\star}}{\\\\|{W}_{F}}\")))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"katex-html\",\n    \"aria-hidden\": \"true\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"base\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"strut\",\n    \"style\": {\n      \"height\": \"1.53em\",\n      \"verticalAlign\": \"-0.52em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mopen nulldelimiter\"\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mfrac\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"1.01em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.655em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"\\u2225\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"W\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.3448em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.3567071428571427em\",\n      \"marginRight\": \"0.07142857142857144em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.5em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size3 size1 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"F\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.14329285714285717em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  }))))))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.23em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"frac-line\",\n    \"style\": {\n      \"borderBottomWidth\": \"0.04em\"\n    }\n  })), mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-3.485em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"3em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size6 size3 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"\\u2225\"), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mathnormal mtight\",\n    \"style\": {\n      \"marginRight\": \"0.13889em\"\n    }\n  }, \"W\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"msupsub\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-t vlist-t2\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.18934285714285717em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"style\": {\n      \"top\": \"-2.357em\",\n      \"marginRight\": \"0.07142857142857144em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"pstrut\",\n    \"style\": {\n      \"height\": \"2.5em\"\n    }\n  }), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"sizing reset-size3 size1 mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mord mtight\"\n  }, \"\\u22C6\"))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.143em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  })))))))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-s\"\n  }, \"\\u200B\")), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist-r\"\n  }, mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"vlist\",\n    \"style\": {\n      \"height\": \"0.52em\"\n    }\n  }, mdx(\"span\", {\n    parentName: \"span\"\n  }))))), mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"mclose nulldelimiter\"\n  })))))), \", then these two \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"views\"), \" are no longer equivalent. And here I think actually going back to the penalised loss function gives better results. For one thing, it's no longer a convex program, amenable to simple solvers.\"), mdx(\"p\", null, \"In our experiments we find that running Adam on this penalised loss function gives great results. My speculation is that this might be the way to solve non-convex programs (I'm sure people have thought about this).\"), mdx(\"div\", {\n    \"className\": \"footnotes\"\n  }, mdx(\"hr\", {\n    parentName: \"div\"\n  }), mdx(\"ol\", {\n    parentName: \"div\"\n  }, mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-Candes:2009kj\"\n  }, \"Candes, E.J. & Recht, B., 2009. Exact matrix completion via convex optimization. Foundations of Computational Mathematics, 9(6), pp.717\\u2013772.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-Candes:2009kj\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")), mdx(\"li\", {\n    parentName: \"ol\",\n    \"id\": \"fn-1\"\n  }, \"I'm pretty sure that people have profitably used this equivalence in this context.\", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"#fnref-1\",\n    \"className\": \"footnote-backref\"\n  }, \"\\u21A9\")))));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"---\ntags:\n - optimisation\n---\n\n# On Optimisation in Matrix Completion\n\nStatisticians get their first taste of optimisation when they learn about penalised linear regression:\n$$\n\\begin{align*}\n  \\min_{\\beta} \\|Y - X \\beta\\|_2^2 + \\lambda\\|\\beta\\|_p.\n\\end{align*}\n$$\nIt turns out that there's an equivalent formulation (as a constrained minimisation) that provides a little more intuition:\n$$\n\\begin{align*}\n  \\min \\|Y - X \\beta\\|_2^2 \\text{ s.t. } \\|\\beta\\|_p \\leq s,\n\\end{align*}\n$$\n\n![The OG image.](https://online.stat.psu.edu/onlinecourses/sites/stat508/files/lesson05/image_09.gif)\n\nwhere there is a one-to-one relation between $\\lambda$ and $s$. This different view provides a geometric interpretation: depending on the geometry induced by the $l_p$ ball that is the constraint set, you're going to get different kinds of solutions.\n\nNote that the above equivalence is exact only when the loss and the penalty are both convex. In the [[matrix-completion]] setting, with our penalty, this is no longer the case.\n\nThe (classical) convex program [@Candes:2009kj] is given by:\n$$\n\\begin{align*}\n  \\min \\|W\\|_\\star \\text{ s.t. } \\|\\mathcal{A}(W) - y \\|_2^2 \\leq \\epsilon,\n\\end{align*}\n$$\nwhere setting $\\epsilon = 0$ reduces to the noise-less setting. The more recent development using a penalised linear model is given by:\n$$\n\\begin{align*}\n  \\min_{W} \\| \\mathcal{A}(W) - y \\|_2^2 + \\lambda \\|W\\|_{\\star}\n\\end{align*}\n$$\nSince they're both convex, you have equivalence just like for the Lasso.^[I'm pretty sure that people have profitably used this equivalence in this context.]\n\n## Non-Convex\n\nWhat happens when we move to non-convex penalties though? Then, I think what you have is a *duality gap* (I could be wrong). If we use our penalty $\\frac{\\|{W}_{\\star}}{\\|{W}_{F}}$, then these two *views* are no longer equivalent. And here I think actually going back to the penalised loss function gives better results. For one thing, it's no longer a convex program, amenable to simple solvers.\n\nIn our experiments we find that running Adam on this penalised loss function gives great results. My speculation is that this might be the way to solve non-convex programs (I'm sure people have thought about this).","excerpt":"On Optimisation in Matrix Completion Statisticians get their first taste of optimisation when they learn about penalised linear regression:…","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[{"frontmatter":{"title":"","tags":["neural_networks","optimisation"]},"fields":{"slug":"/discretization-of-gradient-flow/","title":"Discretization of Gradient Flow","lastUpdated":"1/22/2022","lastUpdatedAt":"2022-01-22T10:54:29.000Z","gitCreatedAt":"2022-01-04T21:27:53.000Z"}},{"frontmatter":{"title":"","tags":["from_paper","lit_review","gradient_descent","optimisation","regularization"]},"fields":{"slug":"/exponential-learning-rates/","title":"Exponential Learning Rates","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["optimisation"]},"fields":{"slug":"/on-optimisation-in-matrix-completion/","title":"On Optimisation in Matrix Completion","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}},{"frontmatter":{"title":"","tags":["optimisation","gradient_descent"]},"fields":{"slug":"/the-unreasonable-effectiveness-of-adam/","title":"The Unreasonable Effectiveness of Adam","lastUpdated":"1/12/2022","lastUpdatedAt":"2022-01-12T12:14:44.000Z","gitCreatedAt":"2022-01-12T12:14:44.000Z"}}]}},"pageContext":{"tags":["optimisation"],"slug":"/on-optimisation-in-matrix-completion/","sidebarItems":[{"title":"","items":[{"title":"Recently Updated","url":"/latest/","collapse":true,"indent":false,"items":[{"title":"01-22: Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"01-22: Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"01-22: Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"01-22: System 1 and 2","url":"/system-1-and-2/"},{"title":"01-22: Vision Transformers","url":"/vision-transformers/"},{"title":"01-16: Estimating the Mean","url":"/estimating-the-mean/"},{"title":"01-12: Alone","url":"/alone/"},{"title":"01-12: Bitter Lesson","url":"/bitter-lesson/"},{"title":"01-12: Calculus-for-Brain-Computation","url":"/calculus-for-brain-computation/"},{"title":"01-12: Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"}]}]},{"title":"Tags","items":[{"title":"GPT","type":"tag","url":"/tags/gpt/","items":[{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus-for-Brain-Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep","type":"tag","url":"/tags/deep/","items":[{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit-Regularisation","url":"/implicit-regularisation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"journal","type":"tag","url":"/tags/journal/","items":[{"title":"2021-12-24","url":"/journal/2021-12-24/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"Dataset Meta-Learning From Kernel Ridge-Regression","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Meta-Learning From Kernel Ridge-Regression","url":"/dataset-meta-learning-from-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus-for-Brain-Computation","url":"/calculus-for-brain-computation/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"paper","type":"tag","url":"/tags/paper/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Meta-Learning From Kernel Ridge-Regression","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"penalty","type":"tag","url":"/tags/penalty/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"}]},{"title":"proj_interpolation","type":"tag","url":"/tags/proj-interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]}]}],"tagsGroups":[{"title":"GPT","type":"tag","url":"/tags/gpt/","items":[{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"artificial_intelligence","type":"tag","url":"/tags/artificial-intelligence/","items":[{"title":"AI for Health","url":"/ai-for-health/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"attention","type":"tag","url":"/tags/attention/","items":[{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"biologically_inspired","type":"tag","url":"/tags/biologically-inspired/","items":[{"title":"Calculus-for-Brain-Computation","url":"/calculus-for-brain-computation/"},{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"causal_inference","type":"tag","url":"/tags/causal-inference/","items":[{"title":"Learning DAGs","url":"/learning-dags/"}]},{"title":"classic_papers","type":"tag","url":"/tags/classic-papers/","items":[{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"commentary","type":"tag","url":"/tags/commentary/","items":[{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"computer_science","type":"tag","url":"/tags/computer-science/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"computer_vision","type":"tag","url":"/tags/computer-vision/","items":[{"title":"Computer Vision Tasks","url":"/computer-vision-tasks/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"data_science","type":"tag","url":"/tags/data-science/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"deep","type":"tag","url":"/tags/deep/","items":[{"title":"Fast Weights","url":"/fast-weights/"}]},{"title":"deep_learning","type":"tag","url":"/tags/deep-learning/","items":[{"title":"GPT-3","url":"/gpt3/"}]},{"title":"economics","type":"tag","url":"/tags/economics/","items":[{"title":"Market for Lemons","url":"/market-for-lemons/"}]},{"title":"finance","type":"tag","url":"/tags/finance/","items":[{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"},{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"}]},{"title":"from_article","type":"tag","url":"/tags/from-article/","items":[{"title":"Bitter Lesson","url":"/bitter-lesson/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Market for Lemons","url":"/market-for-lemons/"},{"title":"Next Steps for Deep Learning","url":"/next-steps-for-deep-learning/"}]},{"title":"from_paper","type":"tag","url":"/tags/from-paper/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Learning DAGs","url":"/learning-dags/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"from_podcast","type":"tag","url":"/tags/from-podcast/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"from_talk","type":"tag","url":"/tags/from-talk/","items":[{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"}]},{"title":"gradient_descent","type":"tag","url":"/tags/gradient-descent/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"graph_neural_networks","type":"tag","url":"/tags/graph-neural-networks/","items":[{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"}]},{"title":"gui","type":"tag","url":"/tags/gui/","items":[{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"}]},{"title":"idea","type":"tag","url":"/tags/idea/","items":[{"title":"One Stock to Rule Them All","url":"/one-stock-to-rule-them-all/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"implicit_regularisation","type":"tag","url":"/tags/implicit-regularisation/","items":[{"title":"Implicit-Regularisation","url":"/implicit-regularisation/"}]},{"title":"interview","type":"tag","url":"/tags/interview/","items":[{"title":"Precision/Recall","url":"/precision-recall/"}]},{"title":"journal","type":"tag","url":"/tags/journal/","items":[{"title":"2021-12-24","url":"/journal/2021-12-24/"}]},{"title":"lit_review","type":"tag","url":"/tags/lit-review/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"machine_learning","type":"tag","url":"/tags/machine-learning/","items":[{"title":"Dataset Meta-Learning From Kernel Ridge-Regression","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Invariant Risk Minimisation","url":"/invariant-risk-minimisation/"},{"title":"Knowledge Distillation","url":"/knowledge-distillation/"},{"title":"Meta Learning","url":"/meta-learning/"},{"title":"Object Detection for GUI","url":"/objection-detection-for-guis/"},{"title":"System 1 and 2","url":"/system-1-and-2/"},{"title":"Transformers","url":"/transformers/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"mathematics","type":"tag","url":"/tags/mathematics/","items":[{"title":"Pseudo-inverses and SGD","url":"/pseudo-inverses-and-sgd/"}]},{"title":"matrix_completion","type":"tag","url":"/tags/matrix-completion/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"}]},{"title":"medicine","type":"tag","url":"/tags/medicine/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]},{"title":"meta_analysis","type":"tag","url":"/tags/meta-analysis/","items":[{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"}]},{"title":"meta_learning","type":"tag","url":"/tags/meta-learning/","items":[{"title":"Meta Learning","url":"/meta-learning/"}]},{"title":"money_stuff","type":"tag","url":"/tags/money-stuff/","items":[{"title":"Monopoly in Tech","url":"/monopoly-in-tech/"}]},{"title":"neural_networks","type":"tag","url":"/tags/neural-networks/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Generalized Neural Networks","url":"/generalised-neural-networks/"},{"title":"Graph Network as Arbitrary Inductive Bias","url":"/graph-network-as-arbitrary-inductive-bias/"},{"title":"Transformers","url":"/transformers/"}]},{"title":"neural_tangent_kernel","type":"tag","url":"/tags/neural-tangent-kernel/","items":[{"title":"Dataset Meta-Learning From Kernel Ridge-Regression","url":"/dataset-meta-learning-from-kernel-regression/"}]},{"title":"neurips","type":"tag","url":"/tags/neurips/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"}]},{"title":"neuroscience","type":"tag","url":"/tags/neuroscience/","items":[{"title":"Calculus-for-Brain-Computation","url":"/calculus-for-brain-computation/"}]},{"title":"nlp","type":"tag","url":"/tags/nlp/","items":[{"title":"Debiasing Word Embeddings","url":"/debiasing-word-embeddings/"},{"title":"Explaining Word Embeddings","url":"/explaining-word-embeddings/"},{"title":"GPT-3","url":"/gpt3/"},{"title":"Signed Word Embeddings","url":"/signed-word-embeddings/"}]},{"title":"optimisation","type":"tag","url":"/tags/optimisation/","items":[{"title":"Discretization of Gradient Flow","url":"/discretization-of-gradient-flow/"},{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"},{"title":"On Optimisation in Matrix Completion","url":"/on-optimisation-in-matrix-completion/"},{"title":"The Unreasonable Effectiveness of Adam","url":"/the-unreasonable-effectiveness-of-adam/"}]},{"title":"overparameterization","type":"tag","url":"/tags/overparameterization/","items":[{"title":"Overparameterized Regression","url":"/overparameterized-regression/"}]},{"title":"paper","type":"tag","url":"/tags/paper/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"},{"title":"Can You Learn an Algorithm","url":"/can-you-learn-an-algorithm/"},{"title":"Dataset Meta-Learning From Kernel Ridge-Regression","url":"/dataset-meta-learning-from-kernel-regression/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"Non-deep Networks","url":"/non-deep-networks/"},{"title":"Overparameterized Regression","url":"/overparameterized-regression/"},{"title":"Stand-Alone Self-Attention in Vision Models","url":"/stand-alone-self-attention-in-vision-models/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Vision Transformers","url":"/vision-transformers/"}]},{"title":"penalty","type":"tag","url":"/tags/penalty/","items":[{"title":"Effectiveness of Normalised Quantities","url":"/effectiveness-of-normalised-quantities/"}]},{"title":"proj_interpolation","type":"tag","url":"/tags/proj-interpolation/","items":[{"title":"Benign Overfitting in Linear Regression","url":"/benign-overfitting-in-linear-regression/"}]},{"title":"psychology","type":"tag","url":"/tags/psychology/","items":[{"title":"Perception","url":"/kahneman-neurips-perception/"},{"title":"Multidimensional Mental Representations of Natural Objects","url":"/multidimensional-mental-representations-of-natural-objects/"},{"title":"System 1 and 2","url":"/system-1-and-2/"}]},{"title":"regularization","type":"tag","url":"/tags/regularization/","items":[{"title":"Exponential Learning Rates","url":"/exponential-learning-rates/"}]},{"title":"research","type":"tag","url":"/tags/research/","items":[{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"society","type":"tag","url":"/tags/society/","items":[{"title":"Alone","url":"/alone/"},{"title":"Stewardship of Global Collective Behaviour","url":"/stewardship-of-global-collective-beahvior/"}]},{"title":"statistics","type":"tag","url":"/tags/statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Meta Analysis vs Preregistration","url":"/meta-analysis-vs-preregistration/"},{"title":"Michael Jordan Plenary Talk","url":"/michael-jordan-plenary-talk/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"},{"title":"Two Cultures","url":"/two-cultures/"}]},{"title":"theoretical_statistics","type":"tag","url":"/tags/theoretical-statistics/","items":[{"title":"Estimating the Mean","url":"/estimating-the-mean/"},{"title":"Theoretical Statistics: Beauty or Banality","url":"/theoretical-statistics-beauty-or-banality/"}]},{"title":"xAI","type":"tag","url":"/tags/x-ai/","items":[{"title":"AI for Health","url":"/ai-for-health/"}]}],"latestPosts":[{"fields":{"slug":"/generalised-neural-networks/","title":"Generalized Neural Networks","lastUpdatedAt":"2022-01-22T12:34:33.000Z","lastUpdated":"1/22/2022"},"frontmatter":{"draft":false,"tags":["neural_networks","machine_learning"]}},{"fields":{"slug":"/computer-vision-tasks/","title":"Computer Vision Tasks","lastUpdatedAt":"2022-01-22T10:54:29.000Z","lastUpdated":"1/22/2022"},"frontmatter":{"draft":false,"tags":["computer_vision","biologically_inspired"]}},{"fields":{"slug":"/discretization-of-gradient-flow/","title":"Discretization of Gradient Flow","lastUpdatedAt":"2022-01-22T10:54:29.000Z","lastUpdated":"1/22/2022"},"frontmatter":{"draft":false,"tags":["neural_networks","optimisation"]}},{"fields":{"slug":"/system-1-and-2/","title":"System 1 and 2","lastUpdatedAt":"2022-01-22T10:54:29.000Z","lastUpdated":"1/22/2022"},"frontmatter":{"draft":false,"tags":["artificial_intelligence","GPT","machine_learning","psychology"]}},{"fields":{"slug":"/vision-transformers/","title":"Vision Transformers","lastUpdatedAt":"2022-01-22T10:54:29.000Z","lastUpdated":"1/22/2022"},"frontmatter":{"draft":false,"tags":["paper","machine_learning","computer_vision","attention"]}},{"fields":{"slug":"/estimating-the-mean/","title":"Estimating the Mean","lastUpdatedAt":"2022-01-16T10:24:03.000Z","lastUpdated":"1/16/2022"},"frontmatter":{"draft":false,"tags":["statistics","theoretical_statistics"]}},{"fields":{"slug":"/alone/","title":"Alone","lastUpdatedAt":"2022-01-12T12:26:42.000Z","lastUpdated":"1/12/2022"},"frontmatter":{"draft":false,"tags":["society"]}},{"fields":{"slug":"/bitter-lesson/","title":"Bitter Lesson","lastUpdatedAt":"2022-01-12T12:14:44.000Z","lastUpdated":"1/12/2022"},"frontmatter":{"draft":false,"tags":["from_article"]}},{"fields":{"slug":"/calculus-for-brain-computation/","title":"Calculus-for-Brain-Computation","lastUpdatedAt":"2022-01-12T12:14:44.000Z","lastUpdated":"1/12/2022"},"frontmatter":{"draft":false,"tags":["neuroscience","biologically_inspired"]}},{"fields":{"slug":"/debiasing-word-embeddings/","title":"Debiasing Word Embeddings","lastUpdatedAt":"2022-01-12T12:14:44.000Z","lastUpdated":"1/12/2022"},"frontmatter":{"draft":false,"tags":["nlp"]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}