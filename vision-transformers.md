---
tags:
 - paper
 - machine_learning
 - computer_vision
 - attention
---

# Vision Transformers

## Summary

Self-attention based architectures

Lots of work in this space

[[stand-alone-self-attention-in-vision-models]]


## An Image Is Worth 16x16 Words

src: [@dosovitskiy2021image]

### Summary


