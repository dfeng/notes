---
tags:
 - from_paper
---

# Embeddings Can't Possibly Be Right

I was randomly reading a paper from a journal whose name sounded legitimate, but actually is one of those predatory journals (and supposedly has an acceptance rate of 90+%, hence why I'm not linking to them). The authors raised something provocative, which I thought was worth debunking.

One of the most profound (yet nowadays seems obvious) insights in NLP is the idea of using embeddings (vectors in Euclidean space) as 


Distributional Hypothesis