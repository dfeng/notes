---
tags:
 - artificial_intelligence
 - GPT
 - machine_learning
 - psychology
---

# System 1 and 2

Update: Kahneman actually talks about this in his NeurIPS 2021 invited talk: [[kahneman-neurips-perception]].

I forget where this was mentioned (either in one of the AI podcast episodes, or this numenta [video](https://www.youtube.com/watch?v=0ZVOmBp29E0)), but basically we can think of GPT-3 as being the first almost perfect copy of system-1 human thinking, which is how Kahneman chose to dichotomise how our brains work---essentially, system-1 is the fast, intuitive thinking, while system-2 is the deliberate, rational, logical thinking.

Pattern recognition is basically system-1, and it's where all the problems of correlation â‰  causation occur, since it's just focused on predicting things by association. And that's basically what GPT-3 is capable of doing.

The question is then how do we get to system-2 thinking, which is pretty much our competitive edge---deliberate thought. Here's a random #idea that I had on my run, and I suspect someone has already thought about: what if system-2 = system-1 + simulation? It seems to me that the crucial piece of the puzzle is basically being able to *simulate* the world, or at least some very crude model of it. Once you have the capacity to simulate the world, then you can run your system-1 inferences, and see how things compare to the truths of your simulation, while also making sure to update your model of the world against reality.