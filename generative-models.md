# Generative Models

I recently gave a talk about [[score-based models]], mostly based off this blog [post](https://yang-song.net/blog/2021/score/).

At its core, generative models produce samples from a (data) distribution. The first distinction to be made is the principle by which you tackle the problem. Treating it as an adversarial problem gives you [[generative-adversarial-networks]]; treating it more probabilistically or likelihood-based gives you basically the rest. However, there's an additional distinction here that I think is underappreciated, which is how you go about producing the samples, which you can do either like a statistician or like a machine-learning person.

A statistician (or maybe more accurately a Bayesian) thinks of the classical approaches to this problem, namely using MCMC to sample from a distribution. That is, the goal is to set up a Markov Chain such that in the limit you have a random process that is effectively generating samples from the distribution. Alternatively, you can think of it as generating *correlated* samples (see this Wiki [page](https://en.wikipedia.org/wiki/Non-uniform_random_variate_generation#Continuous_distributions)). The issues here are how rapidly mixing is this process (or does it get stuck in some region); and maybe equivalently how correlated each sample is.

On the other hand, ML tries to learn a model that takes random noise as input, and then outputs an image. Here, the randomness comes from the input noise.^[A computer scientist would think of this more like a `seed`.] You can effectively think of these models as doing something like what happens when you independently sample from a probability distribution (using [Inverse transform sampling](https://en.wikipedia.org/wiki/Inverse_transform_sampling)): you learn a map from a simple distribution (uniform or gaussian) to another distribution. You forgo the stochastic process for what could effectively be a deterministic function, and you don't have to worry about convergence. The slight downside is that creating multiple samples requires you to restart the whole process. Most generative models fall under this second category.

What's interesting (or confusing) is that you have this duality between score-based models and [[diffusion-models]], whereby they're effectively doing very similar things, except the biggest difference is that score-based models follow (at least theoretically) the Bayesian MCMC perspective, while diffusion models take the ML approach. Except, they're kind of the same thing, no? Or, at the very least, there was a lot of fruitful cross-pollination of ideas, which suggests that fundamentally they're doing roughly the same thing. So how does square with these fundamentally different ways of sampling?

Secondly, if you look at how [[diffusion-models]] progress (this [GIF](https://www.reddit.com/r/StableDiffusion/comments/x63xhm/how_stable_diffusion_paints_your_image_iteration/) gives a good visualization).